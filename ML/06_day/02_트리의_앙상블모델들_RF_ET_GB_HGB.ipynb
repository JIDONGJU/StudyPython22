{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트리의 앙상블\n",
    "- 정형데이터에 가장 뛰어난 성능을 보이는 모델들\n",
    "- 앙상블 모델들은 결정트리(Decision Tree)를 기반으로 만들어짐\n",
    "- 앙상블 모델\n",
    "    - 랜덤포레스트(Random Forest)\n",
    "    - 엑스트라 트리(Extra Trees)\n",
    "    - 그레디언트 부스팅(Gradient Boosting)\n",
    "    - 히스토그램 기반 그레디언트 부스팅(Histogram-base Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트 (Random Forest)\n",
    "- 앙상블 모델 중에 가장 대표격 모델로 안정적인 성능으로 널리 사용됨\n",
    "- 앙상블 모델 중에 가장 먼저 시도하는 모델\n",
    "- 훈련데이터에서 과대적합되는 것을 막아줌\n",
    "- 검증데이터와 테스트데이터에서 안정적인 성능을 얻을 수 있음\n",
    "- \n",
    "- 학습개념\n",
    "- 각각의 결정트리를 랜덤하게 만들어서 숲을 만든다고 보면 됨\n",
    "- 훈련데이터에서 랜덤하게 샘플을 추출하여 훈련을 완료한 후, 다시 원본 훈련데이터에 반환을 함\n",
    "- 랜덤하게 추출 시 이전에 사용된 샘플을 사용할 수도 있음 (중복허용)\n",
    "- \n",
    "- 부트스트랩 샘플(Bootstrap Sample)\n",
    "- 위에 설명한 랜덤한 샘플 추출 시 중복을 허용하여 데이터를 샘플링 하는 방식\n",
    "- 샘플추출 방식\n",
    "    1. 원본에서 랜덤 샘플 추출\n",
    "    2. 훈련 이후 사용이 끝나면 원본에 반환\n",
    "    3. 다시 원본에서 샘플 추출, 이때 중복 값 추출 될수도 있음\n",
    "- 위 순서를 반복하면서 샘플링을 통해 훈련하는 방식을 랜덤포레스트가 적용하고 있음\n",
    "- \n",
    "- 랜덤포레스트는 교차검증을 허용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 불러오기, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4872, 3) (4872,)\n",
      "(1625, 3) (1625,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 08_wine.csv 불러와서 훈련, 테스트데이터 만들기\n",
    "wine = pd.read_csv('./data/08_wine.csv')\n",
    "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(data,\n",
    "                                                                      target,\n",
    "                                                                      random_state=42)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 훈련모델 생성하기\n",
    "- 랜덤포레스트 패키지 : sklearn.ensemble\n",
    "- 랜덤포레스트 클래스(모델) : RandomForestClassifir\n",
    "- 교차검증 패키지 : sklearn.model_selection\n",
    "- 교차검증 : cross_validate()\n",
    "- 교차검증 후 훈련검증결과와 테스트검증결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973316912972086\n",
      "0.8732307692307693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤포레스트 훈련모델\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# 훈련하기\n",
    "rfc.fit(train_input, train_target)\n",
    "\n",
    "# 훈련, 테스트 검증\n",
    "print(rfc.score(train_input, train_target))\n",
    "print(rfc.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.72323346, 0.75011277, 0.72872281, 0.6461935 , 0.6847887 ]), 'score_time': array([0.04448271, 0.05617046, 0.04924107, 0.03955936, 0.05191374]), 'test_score': array([0.88410256, 0.90461538, 0.90349076, 0.89014374, 0.8788501 ]), 'train_score': array([0.99743392, 0.99692071, 0.99846075, 0.99820421, 0.99820421])}\n",
      "test_score 평균 = 0.8922405096614543\n"
     ]
    }
   ],
   "source": [
    "# 교차검증 진행\n",
    "# return_train_score : 검증결과 반환받기\n",
    "scores = cross_validate(rfc, train_input, train_target, return_train_score=True, n_jobs= -1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "print(scores)\n",
    "\n",
    "# 최종 훈련모델의 평가점수(정확도)\n",
    "print('test_score 평균 =', scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23254574 0.49599174 0.27146251]\n"
     ]
    }
   ],
   "source": [
    "# 특성 중요도 조회하기\n",
    "print(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### oob 기능 사용\n",
    "- 훈련에 참여하지 못한 잔여샘플 사용하는 기능\n",
    "- 기본은 사용안함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True,\n",
    "                            n_jobs= -1,\n",
    "                            random_state=42)\n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "print(rf.oob_score)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 엑스트라 트리(Extra Tree)\n",
    "- 랜덤포레스트와 유사하게 작동\n",
    "- 기본적으로 100개의 결정트리를 훈련함\n",
    "- 랜덤포레스트와의 차이점\n",
    "    - 부트스트랩 샘플링을 지원하지 않음\n",
    "    - 훈련데이터 전체를 이용핳여 결정트리를 생성\n",
    "    - 무작위로 트리를 분리함\n",
    "- 사용되는 속성 : splitter = 'random' 무작위속성\n",
    "- 장점\n",
    "    - 과대적합을 막고, 검증데이터의 평가 값을 높을 수 있음\n",
    "    - 특성 데이터가 많지 않은 경우에는 랜덤포레스트와 큰 차이가 없음\n",
    "- 랜덤포레스트는 불순도 등 여러가지 조건에 따라 결정트리를 생성하기 때문에 속도가 느린 반면\n",
    "- 엑스트라트리는 랜덤하게 결정트리를 생성하기에 속도가 다소 빠르다는 장점\n",
    "- \n",
    "- 사용패키지 : sklearn.ensemble\n",
    "- 사용되는 클래스(모델) : ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973316912972086\n",
      "0.8738461538461538\n"
     ]
    }
   ],
   "source": [
    "# 코어 전체 사용, train 및 test 결과값 출력\n",
    "# 교차검증 결과인 train 및 test 결과 확인\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_jobs=-1,\n",
    "                           random_state=42)\n",
    "\n",
    "etc.fit(train_input, train_target)\n",
    "\n",
    "print(etc.score(train_input, train_target))\n",
    "print(etc.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.6149838 , 0.59722304, 0.60463119, 0.55067348, 0.5437386 ]), 'score_time': array([0.06184626, 0.06408834, 0.0611968 , 0.0666244 , 0.06355667]), 'test_score': array([0.89025641, 0.8974359 , 0.89835729, 0.89117043, 0.88501027]), 'train_score': array([0.99743392, 0.99692071, 0.99846075, 0.99820421, 0.99820421])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(etc, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19271256 0.52151148 0.28577596]\n"
     ]
    }
   ],
   "source": [
    "print(etc.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그레디언트 부스팅(Gradient Boosting)\n",
    "- 깊이(max_depth)가 얕은 결정트리를 사용함\n",
    "    - 기본적으로 amx_dpth=3 을 사용\n",
    "    - 결정트리는 100개를 사용\n",
    "- !!! 기존에 다른 훈련모델의 결과가 좋지 않을 때 사용하는 모델 !!!\n",
    "- 기존 훈련모델의 오차를 많이 보완해줌\n",
    "- 성능향상을 위한 모델로 주로 사용됨\n",
    "- 과대적합에 강하며, 일반화(과대/과소적합이 없는 상태)에 강함\n",
    "- \n",
    "- 성능향상 테스트 방법\n",
    "    - 결정트리의 갯수를 조절하면서 테스트 진행\n",
    "    - 학습률을 지원하기 때문에 학습률의 값을 증가시키면서 테스트 진행\n",
    "    - 기본 학습률은 0.1\n",
    "- \n",
    "- 단점\n",
    "    - 순서대로 트리를 추가(랜덤하지 않음)하지 않기 때문에 훈련 속도가 느림\n",
    "    - 이런 느린 속도를 개선한 모델이 히스토그램 기반 그래디언트 부스팅 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 그레디언트 부스팅 모델 생성\n",
    "- 사용하는 클래스(모델) : GradientBoostingClassifier\n",
    "- 객체 생성시 아무것도 안주고 seed값만 \n",
    "- 교차검증시에는 train, test 결과값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894704231708938 0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "\n",
    "scores\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12517641 0.73300095 0.14182264]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습률 적용하기\n",
    "- 학습률이 커지면 트리 보정을 강하게 하기 때문에,\n",
    "- 복잡한 모델을 만들어서 일반화 성능을 떨어뜨리게 됨\n",
    "- 학습률 : learning_rate = 0.1 기본값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512006117505237 0.879719686200179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators= 500,\n",
    "                                learning_rate= 0.2,\n",
    "                                random_state=42)\n",
    "\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "\n",
    "scores\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 히스토그램 기반 그레디언트 부스팅(Histogram-base Gradient Boosting)\n",
    "- 사용하는 패키지 : sklearn.ensemble\n",
    "- 사용하는 클래스(모델) : HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380129799494501 0.8805410414363187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(hgb, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "\n",
    "scores\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토그램 기반 그레디언트 부스팅은 안되는듯\n",
    "\n",
    "# hgb.fit(train_input, train_target)\n",
    "# print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584615384615385"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킷런 이외 다른 패키지에서 지원하는 그레디언트 부스팅 기능 모델들\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614122399872658 0.8834151529510873\n"
     ]
    }
   ],
   "source": [
    "# conda install -c anaconda py-xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xxgb = XGBClassifier(tree_method= 'hist', random_state= 42,)\n",
    "\n",
    "scores = cross_validate(xxgb, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "\n",
    "scores\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "- 마이크로소프트에서 만든 히스토그램 기반 그레디언트 부스트 패키지\n",
    "- 훈련 속도가 매우 빠름\n",
    "- 최신 기술을 많이 적용하고 있어서, 인기가 올라가고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9413484712095832 0.8846461327857632\n"
     ]
    }
   ],
   "source": [
    "# 아나콘다 사용자들 : conda install -c conda-forge lightgbm\n",
    "# 파이썬 사용자들 : pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(tree_method= 'hist', random_state= 42,)\n",
    "\n",
    "scores = cross_validate(lgb, train_input, train_target,\n",
    "                        return_train_score= True, n_jobs= -1)\n",
    "\n",
    "scores\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [문제] 와인 데이터 사용\n",
    "# 와인의 화학 조성을 사용하여 와인의 종류 예측(자유롭게)\n",
    "\n",
    "# 특성 이름을 담고 있는 key 값 = feature_names\n",
    "# 특성 데이터를 담고 있는 key 값 = data\n",
    "# 범주 와인의 종류를 담고 있는 key 값 = target_names\n",
    "# - 범주는 'class_0'과 'class_1'만 사용(0과 1로 변경하여 사용)\n",
    "# - 0 = 레드와인, 1 = 화이트와인\n",
    "\n",
    "# 알콜(alcohol)\n",
    "# 말산(Malic acid)\n",
    "# 회분(Ash)\n",
    "# 회분의 알칼리도(Alcalinity of ash)\n",
    "# 마그네슘(Magnesium)\n",
    "# 총 폴리페놀(Total phenols)\n",
    "# 플라보노이드 폴리페놀(Flavanoids)\n",
    "# 비 플라보노이드 폴리페놀(Nonflavanoid phenols)\n",
    "# 프로안토시아닌(Proanthocyanins)\n",
    "# 색상의 강도(Color intens)\n",
    "# 색상(Color)\n",
    "# 희석 와인의 00280/00315 비율 (00280/00315 of diluted wines)\n",
    "# 프롤린(Proline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine_all = load_wine()\n",
    "print(wine_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine_all['data']\n",
    "target = wine_all['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13) (133,)\n",
      "(45, 13) (45,)\n"
     ]
    }
   ],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(data,\n",
    "                                                                      target,\n",
    "                                                                      random_state= 42)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38ae1ba9371524da054e8e3fbefd778d16b5a8ac7937a3f395010f627bb73919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
