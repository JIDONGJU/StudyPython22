{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534b0814-5582-4dfc-ba6b-43bc0d1874a8",
   "metadata": {},
   "source": [
    "## exe-1) 유방암 양성/음성 여부 판단을 위한 모델 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "72eb6451-1b30-42b8-9a53-c9ca6bf6d38a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "breast_cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a0f7c71b-944a-40b3-adfc-1e12495b6f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9c567573-a5f1-479d-a597-8ce452762957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a599ba9-43c6-4692-a540-a3dd4b16f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(breast_cancer_data['data'])\n",
    "data.columns = breast_cancer_data['feature_names']\n",
    "target = pd.DataFrame(breast_cancer_data['target'])\n",
    "target.columns = ['target']\n",
    "\n",
    "df = pd.concat([target,data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3fa76c44-3d75-4a1b-8a31-72ea6db81a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   target                   569 non-null    int32  \n",
      " 1   mean radius              569 non-null    float64\n",
      " 2   mean texture             569 non-null    float64\n",
      " 3   mean perimeter           569 non-null    float64\n",
      " 4   mean area                569 non-null    float64\n",
      " 5   mean smoothness          569 non-null    float64\n",
      " 6   mean compactness         569 non-null    float64\n",
      " 7   mean concavity           569 non-null    float64\n",
      " 8   mean concave points      569 non-null    float64\n",
      " 9   mean symmetry            569 non-null    float64\n",
      " 10  mean fractal dimension   569 non-null    float64\n",
      " 11  radius error             569 non-null    float64\n",
      " 12  texture error            569 non-null    float64\n",
      " 13  perimeter error          569 non-null    float64\n",
      " 14  area error               569 non-null    float64\n",
      " 15  smoothness error         569 non-null    float64\n",
      " 16  compactness error        569 non-null    float64\n",
      " 17  concavity error          569 non-null    float64\n",
      " 18  concave points error     569 non-null    float64\n",
      " 19  symmetry error           569 non-null    float64\n",
      " 20  fractal dimension error  569 non-null    float64\n",
      " 21  worst radius             569 non-null    float64\n",
      " 22  worst texture            569 non-null    float64\n",
      " 23  worst perimeter          569 non-null    float64\n",
      " 24  worst area               569 non-null    float64\n",
      " 25  worst smoothness         569 non-null    float64\n",
      " 26  worst compactness        569 non-null    float64\n",
      " 27  worst concavity          569 non-null    float64\n",
      " 28  worst concave points     569 non-null    float64\n",
      " 29  worst symmetry           569 non-null    float64\n",
      " 30  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a0074-be72-4640-bee4-1973b8d91a60",
   "metadata": {},
   "source": [
    "### 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c19174b3-3786-43a9-9747-97f9a6657051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(143, 30)\n",
      "(426,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# 종속변수 독립변수 분리\n",
    "data = df.iloc[:,1:].to_numpy()\n",
    "target = df['target'].to_numpy()\n",
    "\n",
    "# 훈련/테스트 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data, target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd46031-2764-4343-9dbc-aab736f59726",
   "metadata": {},
   "source": [
    "## 로지스틱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce38af01-89bc-4b6a-b170-f7d54f4d71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b055abbc-2a17-4f46-9ceb-034dc6505918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_0_1 = train_target[(train_target == 0) | \\\n",
    "                                  (train_target == 1)]\n",
    "target_0_1.shape\n",
    "\n",
    "train_0_1 = train_scaled[(train_target == 0) | \\\n",
    "                                  (train_target == 1)]\n",
    "train_0_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d309196-82cf-4767-9b6f-f60238a5d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 =  0.9859154929577465\n",
      "[[-0.39751679 -0.41535774 -0.34832129 -0.45142016 -0.20791905  0.62039231\n",
      "  -0.73558933 -1.09376305  0.23601875  0.08357971 -1.28501592  0.22136641\n",
      "  -0.58858571 -0.89527827 -0.19689721  0.63403697 -0.14135554 -0.40058728\n",
      "   0.5262862   0.73327971 -0.84378886 -1.29571675 -0.51790962 -0.82723207\n",
      "  -0.53895662  0.12288567 -1.00748469 -0.76642547 -1.21963558 -0.14580732]] [0.54105702]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_0_1, target_0_1)\n",
    "print(\"정확도 = \", lr.score(train_0_1, target_0_1))\n",
    "\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d381497-7854-4eb2-8e85-c4c931fc6e6c",
   "metadata": {},
   "source": [
    "## 결정트리\n",
    "##### - 최적의 max_depth값 확인 필요 -> 6이 최적값으로 출력\n",
    "##### 그리드서치 진행 후 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7af8b475-2cf2-46cf-a186-6651d6bddcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련정확도= 0.9976525821596244\n",
      "테스트정확도= 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=6,random_state=42)\n",
    "dt.fit(train_scaled, train_target)\n",
    "print(\"훈련정확도=\", dt.score(train_scaled, train_target))\n",
    "print(\"테스트정확도=\", dt.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5cf01-a550-4634-96ac-dd90798a62a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 변수중요도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46c3497f-5502-4458-a22f-8017360c8886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02601101, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.69593688, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01277192, 0.00155458,\n",
       "       0.        , 0.00670697, 0.01702539, 0.        , 0.        ,\n",
       "       0.0877369 , 0.10787925, 0.        , 0.03452044, 0.00985664,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = dt.feature_importances_\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb5f1eaf-acf5-4e28-8619-c26bee053682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.695937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worst texture</td>\n",
       "      <td>0.107879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.087737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.034520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>0.026011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points error</td>\n",
       "      <td>0.017025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area error</td>\n",
       "      <td>0.012772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worst smoothness</td>\n",
       "      <td>0.009857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.006707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness error</td>\n",
       "      <td>0.001555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  importances\n",
       "7    mean concave points     0.695937\n",
       "21         worst texture     0.107879\n",
       "20          worst radius     0.087737\n",
       "23            worst area     0.034520\n",
       "1           mean texture     0.026011\n",
       "17  concave points error     0.017025\n",
       "13            area error     0.012772\n",
       "24      worst smoothness     0.009857\n",
       "16       concavity error     0.006707\n",
       "14      smoothness error     0.001555"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnames = pd.DataFrame(breast_cancer_data['feature_names'])\n",
    "list = dt.feature_importances_\n",
    "df_list = pd.DataFrame(list)\n",
    "df_concat = pd.concat([df_fnames, df_list], axis=1)\n",
    "# np.sort(list)[::-1]\n",
    "df_concat.columns=['name', 'importances']\n",
    "df_concat.sort_values('importances', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c830c0f-f661-4e2e-ba6c-10e1166d6f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 3)\n",
      "(143, 3)\n",
      "(426,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# 독립변수 선택하기\n",
    "data = df[['mean concave points', 'worst texture', 'worst radius']].to_numpy()\n",
    "target = df['target'].to_numpy()\n",
    "\n",
    "# 훈련/테스트 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data, target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e67d2-6402-48c5-bc5c-9d7f9acf0ebf",
   "metadata": {},
   "source": [
    "### 그리드서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "729f13e3-d9f9-483b-9bb7-67f80af7fce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 score =  0.9365800273597811\n"
     ]
    }
   ],
   "source": [
    "# 최적의 max_depth값 찾기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "params = {\"max_depth\" : range(5, 20, 1)}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                 params, n_jobs = -1, cv = splitter)\n",
    "gs.fit(train_input, train_target)\n",
    "print(\"최종 score = \", np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7e6b60dd-0795-4983-9a7c-1652f17f7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=6, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "17bb8b10-418f-408a-8867-86308af58f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth         0        1         2         3         4\n",
       "0          5  0.967213  0.95082  0.950820  0.901639  0.901639\n",
       "1          6  0.967213  0.95082  0.967213  0.918033  0.901639\n",
       "2          7  0.950820  0.95082  0.967213  0.918033  0.901639\n",
       "3          8  0.950820  0.95082  0.967213  0.901639  0.901639\n",
       "4          9  0.950820  0.95082  0.967213  0.901639  0.901639"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params = pd.DataFrame(gs.cv_results_[\"params\"])\n",
    "df_total = pd.DataFrame()\n",
    "for i in range(0,5,1):\n",
    "    df_score = pd.DataFrame(gs.cv_results_[f\"split{i}_test_score\"])\n",
    "    df_total = pd.concat([df_total, df_score],axis=1)\n",
    "df_total\n",
    "df = pd.concat([df_params, df_total], axis=1)\n",
    "df.columns=['max_depth',0,1,2,3,4]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34592e-8970-41d6-905a-d34c714c642a",
   "metadata": {},
   "source": [
    "### 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4d8d671b-63ed-4540-b014-5e96a7fc9f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 score =  0.9988269794721407 0.9365800273597811\n"
     ]
    }
   ],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# dt : 결정트리 훈련모델(다른 모델을 사용한 경우 해당 모델)\n",
    "# 두번째값 : 훈련데이터(fold에서 훈련데이터 쪼갤때 사용)\n",
    "scores = cross_validate(dt, train_input, train_target,\n",
    "                       return_train_score=True)\n",
    "# print(scores)\n",
    "\n",
    "### 딕셔너리의 test_score의 평균값이 최종 훈련모델의 평가점수(정확도)\n",
    "import numpy as np\n",
    "print(\"최종 score = \", np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb11a0f-b022-4fa5-91c6-eb9b12363d68",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "##### - 최적의 max_iter값 확인 필요\n",
    "##### max_iter : 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56c9fe1d-b902-451d-ad0d-47335f3314ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련정확도 =  0.9882629107981221\n",
      "테스트정확도 =  0.965034965034965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 클래스(모델) 생성\n",
    "sc = SGDClassifier(loss=\"log\", max_iter=100, tol=None, random_state=42)\n",
    "\n",
    "sc.fit(train_scaled,train_target)\n",
    "\n",
    "print(\"훈련정확도 = \", sc.score(train_scaled, train_target))\n",
    "print(\"테스트정확도 = \", sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "342aeba1-3abb-44d3-85a5-17d948adf578",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sc = SGDClassifier(loss=\"log\", random_state=42)\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "# 범주 고유값\n",
    "classes = np.unique(train_target)\n",
    "\n",
    "# 반복을 300회 이상으로 테스트하여 정확도를 리스트에 저장\n",
    "for _ in range(0, 300) : \n",
    "    sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "    \n",
    "    train_score.append(sc.score(train_scaled, train_target))\n",
    "    test_score.append(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fdf92aa4-27c3-4403-a3b5-604391b8852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtw0lEQVR4nO3deXRb9Zn/8fcjWbYjL7HjLAQcskAo2UM2aClLSkkIpaUp07JOOykUaIFhmB+loQsdpp0Dw3QotKVwaEunhf6gQEt/tIQSYJLJlBMgO2SDhCzEcUIcx1u8S3p+f9wrWbJlW4nlyNZ9Xuf4WLqL9L0RfPT1c7/3e0VVMcYYk718mW6AMcaY/mVBb4wxWc6C3hhjspwFvTHGZDkLemOMyXI5mW5AMsOHD9dx48ZluhnGGDNorFu37rCqjki2bkAG/bhx41i7dm2mm2GMMYOGiOztbp2VbowxJstZ0BtjTJazoDfGmCxnQW+MMVnOgt4YY7KcBb0xxmQ5C3pjjMlyA3IcvTHp8t7BBl56pzLTzTAmJcG8HG6+4LS0v64FvclqP1r+Hq9u/QiRTLfEmN4NL8yzoDfmWKgq6/fWcMWscv7zSzMy3RxjMsZq9CZr7a1uorqxjdljSzPdFGMyynr03QiFI/h9gtjf/BmjqoQjx3+ryzV7jgBY0BvPs6B3PfDX7Rysa+HBK2fyk9d38OCr7/OJ08r4v187h9+9tZc/b6rki7PH8NRbe3nhG+dmurme8PlH3mBTRV2fXqMoP4eJIwvT1CJjBicLetfavTVUH20F4L2PGgB4d78TMlsq61m/t5YzTypmw4e1hCOK32c9/f50oK6ZTRV1LJg8immnDD3u15lWPhSffVbG4yzoXbVNbbS0RwBodX83tYVRVVrawrSFI9S3tLvLQxTlBzLWVi9Yv7cWgFvmn86MMSUZbYsxg52djHXVNLXT3B4GoDXk/A5HlJb2SGz54aNtADS3hTPTSA9Zt7eG/ICPyScXZ7opxgx6nunRr/6gmpJggEmjuwaHqlLT2EZujvO9F+3RAzS0tNMSDfoGp7TT2EvQN7aGeHFTJVfNHZP0ZG44ojyz5kOumFVOfsB/3MeUafUt7fzXG3tiX4zptHzrQWaUlxDwW1/EmL7yTNBf/Ys3Adhz/2e6rDvaGiIUUcLtTqkmPrgaWkNxPXon6JvaQj2+17Nr93Hvn7cyo7wkaY901Y4qvvPCZoYX5rFwyknHfUyZ9uLGSh589X1ndFKaX1sEbvjk+DS/qjHe5Jmg70ltk1N7V4XWUISW9gi5fh9t4QgNLSGa3R5+daNTumnqpUe/bm8NAJW1zUmDfr27/oj7eoPV+r01DC/MY813LrJhqMYMYJ74uzgUjvS4vqapI3Bb2yO0hsIML8wF4GhLiNb2jpo9OKWZnkSD/EBdc9L10S+C+PcdjNZ9WMPssSUW8sYMcJ7o0dc1t/e4Pr5n3dwepjUUYURRHpV1LTS0dJykjW3TQ4++sraZyroW57H7O14oHGHjvlqg4y+JTOlLbf1IYxt7q5u49uxT09giY0x/8ETQ99Zzjg/c5vYwLe1hhhfmAU6NvqVT0D+9Zh8Pvvo+f/2n87uMp9/khrhP4EBtR4/+g6qjfOmx1Xz/c1NipZ9Mlm7+45XtPLLigz6/jl11aszA55Gg77nnHP9F0OL26MsKnNJNQ0uoSw/+zV3VtIUiHD7ayqji/IR1B+udXvxpIwoTevTvVtRR3djGj199H4DSYIDaDJZuXtt6iDNPKuKzM04+7tcoCQaYdaoFvTEDnTeCvpeec02S0k2Z26M/2hKKXUgV1RZynlfWNncJ+pqmdkTgYycVsamiNra80q3X7z7cyKjiPE4fWdjrF1B/qWtu5/1DDfzzp8/glvmnZ6QNxpgTxxMnY6M99u7OGcYH7tGWEOGIUpDrJ5jrp665nbZuTuYeSFKDr2lsY+iQAOWlQQ7WtRBxT+AeqO3YdvbYUkqCub1+AfWXDR/WoGplF2O8whs9ejfIC3I7DnftniOICOGI8uSbe2PLa90Tt3kBH0X5OVS5Y+eTqaxtpqqhlVXvV3HF7HL3vdooDeZyckk+7WFlf20zK947REVNU2y/WaeWsre6icNHW/n5yp00t4W5/pPjKQnmpnQ8f9qwn20H65OuWzjlpC7llLd2VfPf7x2KPX9nXx0+waYWMMYjPBL0Ts85/rzpv/5lK/k5fnzu3zQzx5SwcV8tde62eTl+CvNyqGro2muPOlDXwrNr9/Efr7zHeROHM7I4n9qmdkqDgVhJ58FX3+eFDfsBOGNUIW2hCJ86cyR/2rCf+pYQD/z1PQBKgrlcn8IFQs1tYe58bhNAlxPBbeEI6/fW8NzNn0hY/q9/2cq2A/UJV5leNGkUBXme+PiN8TxP/J8eLZHEl2D21zRTEgzg9wkLp4ziO5dO5vz/WBEbgZMf8FGUH6Cqofse/YG65tjQy/21zYwszqemqY2TivMZ5p7MjT/hOnfcMP5t8TSAhN57YV4O6z+s4Xp6D/pNFbWEIsqv/2Eu888cmbDuB3/ZylNv7qUtFIlN59DYGmLbgXpunX86/7zgY72+vjEm+3ikRu+Ed/Qkakt7mOrGNmqb2qlpaqc0mEt+rvNPESvd5Pgpys/hUA9BX1nbEhtCGa3X1zS2URLMpTTozG55sL5j/5NLhsQelxY463N8wvwzR8YusupN9GKrs04t6bJu9thSWkMRth3oKOts2ldLRGGW1eON8SxPBH20Vx1R54Klg24o1za3U9vkBHN0crFojz4vx6nRN7QkXgWb45ZLRJwafTTgK93Ar2lqZ1hBINZj3334aGzf0UM7RuiUDHHWjx9ewOxTSzhQ18Le6sYubQ+FIzS1hWI/a/cc4fSRhUnr+dGTq2/uqo5t/+Zu5y5LZ9kwSGM8K6XSjYhcAjwM+IFfqur9ndaXAk8ApwEtwFdVdbO77g7gBkCBd4Elqtp94buPVJXLH3mDz04/ma+dPwFIHFXTFo7EhjqGI0oYGFYQYIgb9HXNzpdCfsBPUV7XOeeHF+ZxsL6F8WUF7K5ujF38dKCuhZb2MM3tYUqCuZQMcfaNH5pZXhqMPY5+sZw3cQRzxg0D4MIfreShK2dy37Lt/PDzUznvjOGc9+8ruvxVceWcMUmPfVRxPuWlQ7jv5e3c9/L22PIzRhUydIjNn2+MV/Ua9CLiBx4BLgYqgDUi8qKqbo3b7NvARlVdLCJnuttfJCKnAP8ITFbVZhF5FrgK+K80H0fM/tpm3qmo45S4Mkl93BQIre2RhKGO4NTLA34fOT5J6NGPKMqLbVOYl8PR1hDDi3I5WN/CJ04vY9fhRo66894crGuJnfQtDeaS4/dRnJ9DfUuIj40q4tZPnc6cuPLJOROG8bNrzmLB5JMI+IUH/m469764hR+/+j4H61vYuK+W0oJcDjW0cvW8MYwrKwCcvyQ+M737i5weunJmrLwTdfaEsmP6NzTGZJdUevTzgJ2qugtARJ4BLgfig34ycB+Aqm4XkXEiMiruPYaISDsQBCrT1fhk4meOjGpoCVGQ66fRvVNU58nGSt0ySH7AnzC8cnRJR6mlrDDXCXr3QqqLJo3iqTc/jK2vrGumptHZd5hbfy8tyKW+xfly6HwFqohwWVxgf2nOGP68qZL/3XE49nrRuv0/X/yxhC+dnswZNyz2F4IxxkBqNfpTgH1xzyvcZfE2AV8AEJF5wFigXFX3Az8CPgQOAHWqujzZm4jIjSKyVkTWVlVVHdtRxImGY3T6gVDYuUPUMHc2yrZQpMtkY9Fgzg/443r0fk4eOiRuG2f/aNBPHFnI2DKnFDO2LMiB2pbYuYBo/Tz6uzTF8fHx498P1Lawbm8NY8uCKYe8McYkk0rQJ7ueVDs9vx8oFZGNwG3ABiDk1u4vB8YDJwMFInJdsjdR1cdVdY6qzhkxYkSq7e9i3Yc13JfzC37X+o9EfnY2reufAaCswAnL1lCEA7XN3JL3Mkv8L/Nl/yuM2/5LAIbk+mJlnvzOPfqCXPw+iY2mGVaQGwvm2aeWcqihJXZxVfRLYZi7bcpBH1faOVDX7EwDbCdRjTF9lErppgKIP/tXTqfyi6rWA0sAxJmcfLf7sxDYrapV7ro/Ap8Anupzy5NQVXZ8dJTLct6kKjIUavfCB/8NLI7NL98aClPT1M4VgTeoVyGMj6E7ArDwLvJz/LGx9nk5fkbEncD85OnDY9MGbDvQwJCAn8/OGM2e6kbOmVDGHzfsZ8V25+rTUUXOF0RprEef2onQ2WNLmTy6mECOLzYLpg2LNMb0VSpBvwaYKCLjgf04J1Ovid9AREqAJlVtwxlhs0pV60XkQ+AcEQkCzcBFwNo0tj9BdEKyvJwwyyNz+UpwM6F2p5cd7dG3hSKoKkO1Ab8IEfXhdys5Q3I77t+al+OcTI26cu6p/MO5zgVNl0wdDcCnzhzFp84cxe7DzrDIv7xzgNNGFDDUDfbOJZzeFOblsOz28/j1G7tjQW/z0Rhj+qrXoFfVkIjcCryCM7zyCVXdIiI3u+sfAyYBvxWRMM5J2uvddW+JyPPAeiCEU9J5vF+OhOgwSiVAO234adMcwm7Qx9foFSiM1JMrfsLiQ5rbQDXhRt15AX/CnZPycrqvco0rCzKsIJcjjW0JwRyt/UdLOaka7Z4bKMzL4YxRRce0rzHGdJbSOHpVXQYs67TssbjHq4GJ3ez7feD7fWhjymoa2/ATQVDaNECr5uCL9ejdoA9HCESaydNW8oAIAmGFtqOxsfTQNdh9vmSnKhwiwqxTS3lt20cJQd/Roz+2Mewnu+cGzjq1pMt8NsYYc6yy6srYmqY2cnFOpvoDubRE/ERCTtBHR8u0tkcoDDfE9vFFzys3HUka9D315OPNGeeemB3bMbQxOlrmWEfNRK8BsLKNMSYdsmpSs5qmdgI4FzDlDwnSFPGTF3KGPJYVdvToiyJJpvhtquaMUYX8dYvzNFq2WfnNCxPG5Hfn788Zy2kjCjl9ZGFs2afOHMlj181m8ujiYzqOssI8fr1krgW9MSYtsivoG9vIc4O+YMgQGut9lIYShzy2hboJ+uYjzBpb3mXx6KFDYjXznhTk5XDx5FEJywJ+H5dMPelYDwOA+R8b2ftGxhiTgqwr3UR79AXBIEdDPgi34/dJbK6X1lCYokhD152bjtjEX8aYrJRVQV/b1M6wfKfmXlQQpDHsR8OtFOXnkJfj1N/bQhGKtK7rzk1HbOIvY0xWyqrSzZHGNsqGCDRDcWEBB8khEmqjMC8ndiOO1lCEIk3Wo68G4KYLJnSZ9MwYYwazrAr6mqY2hucBzTC0qIB9moOEWikqDsRGz7SFIwyL1NHkKyDoV4iEILcAmp152+9eNCmDR2CMMemXVUFf29TOGW7pZlhRIW0EyCFEUV4Oue79UlvbIxRrA43+oQSH+JygzyuM9eiNMSbbZFWN/qK6PzA3tBGA0uJC2sghl3ZmsQ3fmz/jpsBLFDfsZKjW0+gfCsFhECxzfra8APvedl7oyG6o6LeZGowx5oTKqh79je2/o6HRGSKZm5tPTm4egXCYJUd+DMs/5G4/bNtXSUSbaPEVwylTnR69Pw/2vQV/uQO+/gasvA8q1sA/bsjwERljTN9lTdCrKr68ICU+9+KmnFwumlJO/uYQuYFWmHQN72/6GxJuQ4ig4oPPPhzdGVpqYff/Os+PfgQtScbaG2PMIJQ1QS8i5A8pgmb3Nnr+XE4uKwEN42tvhPxiIpJDRBWfKhHxxe8MJac6J2RVnXp9yEbeGGOyQ1bV6AkMgTZ36KQ/D/zuuPi2oxAYgooPjUQARTsferDMKeO0NkBTDbQ3OaFvjDGDXJYFfccdofAHICduMrFAEEFAI85EZtJpVsgh7mRkTdXOj0Yg3Nb/bTbGmH6WZUEf7Hickwf+uHngA0NAfKhGnBp9sh49QH0lhNw6f3vvk5kZY8xAl2VBHzf5mD83Mehz8lERfOrMV9+lRx90e/TVOzqWWdAbY7JAlgV9XI++c9AHgkTwAYqool2C3u3RH44P+qZ+a6oxxpwo2RX0OfE1+lzI6VS6QRBVp0ff+dCHuDNXVu/sWGY9emNMFsiuoO+pdBMY4vbiI/ii4+jj5ZeA+BJ79DbE0hiTBbIs6N3SjS8HfD5niGVs3RAUH+LeUxY6lW58PqdXf+SDjmVWujHGZIEsC3q3dBPtyfvj5pcPBFEEUdwrY5PcdDtap4+y0o0xJgtkWdC7Pfpo0Od06tFLtEePU6bpLDqWPsqC3hiTBbIs6N0afaxHHz+80jkZi2rycfQAhSMS94sG/eqfw2Pnwdon4Gdz+6XpxhjTX7Jmrhugo0cf7cknORkrGsGnmrxHf9H3Yey5UHwyPPvljhr9wXfg4LtQuQEOvw9tTZAb7Lq/McYMQNkV9NHhldHafOegx4cQHV6ZxPCJzk+Le0/ZaI++6Qigzjz14Ex+ZkFvjBkksrR04/boczoHfdw4+mQ9+ti2bohHp0KI3n0qOvTS7kZljBlEsizooydjk/Toc/JBBMGZ1KzLOPp4/gCIv6NH795PlqMHnd9NR9LbbmOM6UdZFvRuj75zjT4QBJG40k2SC6a6vFYwrnTTqQffbEFvjBk8sjPoO4+6cZer+EAVn1PE6f212pshHOqo2UdZj94YM4ikFPQicomIvCciO0VkaZL1pSLygoi8IyJvi8jUuHUlIvK8iGwXkW0i8vF0HkCC7oI+xw16xB1H380FUwmvle8EffSOVfEs6I0xg0ivQS8ifuARYBEwGbhaRCZ32uzbwEZVnQ58GXg4bt3DwF9V9UxgBrAtHQ1PqrsLpqJfACJub56eT8ZGX6u9KXmZxk7GGmMGkVR69POAnaq6S1XbgGeAyzttMxl4HUBVtwPjRGSUiBQD5wO/cte1qWptuhrfRaxG7wa9z+8Eemyys+jJ2EgKQe+WbpL13q1Gb4wZRFIJ+lOAfXHPK9xl8TYBXwAQkXnAWKAcmABUAb8WkQ0i8ksRKUj2JiJyo4isFZG1VVVVx3gYrpxOpRtwhlom1OhJPqlZZ4GgM3tltPce/WIQn/XojTGDSipBnywRO19xdD9QKiIbgduADUAI54KsWcCjqnoW0Ah0qfEDqOrjqjpHVeeMGDEixeZ30nkcPTihHw16d/bKXodXgjMcM750UzK247fV6I0xg0gqQV8BjIl7Xg5Uxm+gqvWqukRVZ+LU6EcAu919K1T1LXfT53GCv390vjIWnDJOtHYfN44+9dKN23sfPrHjt5VujDGDSCpTIKwBJorIeGA/cBVwTfwGIlICNLk1/BuAVapaD9SLyD4R+ZiqvgdcBGxN5wEk8Pmc8k1C6SY34WRsx5WxKZRuavbChqecL5DiUwCBYRNgx3J49R749L29v44XNB6Gvy612T6N6av8ofD5n6f9ZXsNelUNicitwCuAH3hCVbeIyM3u+seAScBvRSSME+TXx73EbcDvRCQX2AUsSfMxJJqzBE77VMfzs66DEWc6x+JeMJVSj/6MhXDI/U6acTWceZlzQ5MzFsJbj8EbD8P5d0FeYT8dyCCy9w149zkom5g4NbQx5thEb2maZilNaqaqy4BlnZY9Fvd4NTCxm303AnOOv4nH6JL7Ep/P/3ZHW6TjytheT8ZO+zvnJ97ETzu/P/dTePE2p4RjQd9R3vrKn6F4dGbbYozpIruujO2N+JxpilPp0fckeicqOynriP47BIf1vJ0xJiO8FfQQm6a411E3PYneicqGWTqajkCgwMo2xgxQngr6aI3eL4r05SRqtEefbHoEL2o+0vV+u8aYAcNTQY/4nKtinSfH/zpB69EnaKqGYP+cRDLG9J2ngl7Fh5+w86QvpZv8EkCsRh/VZD16YwYyTwU9IvjU7dGL//hfx5/jjHe1Hr2jqbrjvIUxZsDxVtAj+N3STa/TFPcmWGZXyEZZjd6YAc1bQR9XupG+lG7AqdNbj77jxiw2tNKYActTQa/S0aPv89QFwTKr0UPHyCPr0RszYHks6H1xQd/HQx8yzIZXQkf5qp8u3TbG9F1KUyBkC0HwiTPDcp8umAKnVNFYBe+9DIWj4JReJuVUhY+2wKgpztwwrQ3O8pw8GHc+VK4fnKWgqvec39ajN2bA8lTQx4d7n2v0JWOdG5M8fZUzgudbu52RON2pWAO/uhgu+zH85Y7EdZf+CJbd2bf2ZFrJqZlugTGmG54K+sRKVR9r9HOvh1PPgfdfgRU/dKbq7Sno69ybdO172/n9hV9AwXB4cjHsX+csW/QAjJnXt3ZlQl4xlJ2W6VYYY7rhraCP78X7+tij9/lh9HQ4+pHzvKm657CLnrg9vMP5feo5UDQ6cdkpc+Dks/rWLmOM6cRTJ2MTRtqk64YhsQnOehmBE11fvaNjP3/A6Q1Hl9k0AsaYfuDhoO/DlbHxouHc24nU6PqWOueuV7nuPdKHlDrLwK4uNcb0C48FfT8cbmwmy1569PHrg2UdXzrR/cXfc43fGGOOk2eDXtLVo88rdm4xmGqPHhJ77tErSoPD7P6zxph+4amgTxg770tTqIo4wZ1qjR4SpwuI9uhtHLoxpp94Kujjh1SmrUcPqc17013QR3v3Vp83xvQTbwV9fI8+nWWSYFnv0yF0rtF3fmyTghlj+omHgz6Nhz6ktOfSTagV2o6C372nakKN3h21Y0FvjOknHgv6fhhHD+5Mlj2UbqJfAtELqpL26K1Gb4zpH94Kevph1A04vfHmI87EZclEyzZlp3dsH2U1emNMP/PuFAjp7tFHQvDAhOSvGw45v4ef0bF9/L6dlxljTBp5K+h98aNu0hj0UxZD3X6ItHe/TW4hnHs75BXC+PM7lo+cDAv+DSZdlr72GGNMHG8FfcI4+jSWboaWw6L7U9v2k52mKPb54BO3pq8txhjTiadq9JIwNbFdhWqM8QZPBX3CjUfS2aM3xpgBLKWgF5FLROQ9EdkpIkuTrC8VkRdE5B0ReVtEpnZa7xeRDSLyl3Q1/HiIr59OxhpjzADWa9CLMw7xEWARMBm4WkQmd9rs28BGVZ0OfBl4uNP624FtfW9uH6XzVoLGGDNIpJJ284CdqrpLVduAZ4DLO20zGXgdQFW3A+NEZBSAiJQDnwF+mbZWH6+4cO/zzcGNMWaQSCXtTgH2xT2vcJfF2wR8AUBE5gFjgXJ33UPAXUCkLw1Nj7jhlX29laAxxgwSqaRdsmJ250tA7wdKRWQjcBuwAQiJyGXAIVVd1+ubiNwoImtFZG1VVVUKzToOCb14C3pjjDekMo6+AhgT97wcqIzfQFXrgSUA4lyJtNv9uQr4nIhcCuQDxSLylKpe1/lNVPVx4HGAOXPmdDOXQN/EXyTls5OxxhiPSKVbuwaYKCLjRSQXJ7xfjN9ARErcdQA3AKtUtV5V71bVclUd5+7338lC/oSJn9/GSjfGGI/otUevqiERuRV4BfADT6jqFhG52V3/GDAJ+K2IhIGtwPX92ObjljDtgZ2MNcZ4REpTIKjqMmBZp2WPxT1eDUzs5TVWAiuPuYXplDCO3oLeGOMN3ko7q9EbYzzIY0HfUaO3KRCMMV7hqaCX/rrDlDHGDGCeCvp+m6bYGGMGMM8Gvc11Y4zxCk+lnSQEvZVujDHe4K2gT7iVoKcO3RjjYR5LO7vxiDHGe7wV9HbjEWOMB3kq6BNq9D4LemOMN3gq6BOnPbDSjTHGGzwV9AnTFPs9dejGGA/zVNqJTWpmjPEgb6Vd3Fw3Pgt6Y4xHeCvtbK4bY4wHeSrofQmjbjx16MYYD/NU2lmN3hjjRd5Ku7hw99mVscYYj/Bs0NtcN8YYr/BU2sWPo7cavTHGKzyVdvHhbtMUG2O8wltBHzeO3u4wZYzxCk8FPXETmflsUjNjjEd4Kujje/Rik5oZYzzCY0EffzLWevTGGG/wVtDHj7SxUTfGGI/wVNrFB71dMGWM8QpPBT0JNXor3RhjvMFTQZ9w4xHr0RtjPMJTQZ8wB73V6I0xHpFS2onIJSLynojsFJGlSdaXisgLIvKOiLwtIlPd5WNEZIWIbBORLSJye7oP4Jj4bJpiY4z39Jp24gw+fwRYBEwGrhaRyZ02+zawUVWnA18GHnaXh4D/o6qTgHOAW5Lse8L4bAoEY4wHpdKtnQfsVNVdqtoGPANc3mmbycDrAKq6HRgnIqNU9YCqrneXNwDbgFPS1vpjZTV6Y4wHpRL0pwD74p5X0DWsNwFfABCRecBYoDx+AxEZB5wFvJXsTUTkRhFZKyJrq6qqUmr8sYoPd5um2BjjFamkXbIah3Z6fj9QKiIbgduADThlG+cFRAqBPwD/pKr1yd5EVR9X1TmqOmfEiBGptP3Y2Y1HjDEelJPCNhXAmLjn5UBl/AZueC8BEKf4vdv9QUQCOCH/O1X9YxrafNx8djLWGONBqaTdGmCiiIwXkVzgKuDF+A1EpMRdB3ADsEpV693Q/xWwTVUfTGfDj0fCfPQ2140xxiN67dGrakhEbgVeAfzAE6q6RURudtc/BkwCfisiYWArcL27+7nA3wPvumUdgG+r6rL0Hkaq4ko3VqM3xnhEKqUb3GBe1mnZY3GPVwMTk+z3N5LX+DMiWrqJqNjwSmOMZ3iqWyvuCdgIgs+C3hjjEZ4K+mi5RhEs540xXuGpoI+egI1gpRtjjHd4Kuijc93owDltYIwx/c5TQe+TaI3eU4dtjPE4TyVedBx9xHr0xhgP8VjQRwPegt4Y4x3eCnqxHr0xxns8FvQd4+iNMcYrPBX0vtioG08dtjHG4zyVeNGpiTvPsWyMMdnMY0FvPXpjjPd4K/Hcq2EjdlWsMcZDPBX0Pp8QUbErY40xnuKtoBchggW9McZbPBX0Is48NzYFgjHGSzyVeNajN8Z4kaeCvqNHb0FvjPEObwW9W7ax4ZXGGC/xVOL5xC6WMsZ4j8eC3unR28lYY4yXeCrxojV6tQumjDEekpPpBpxIEht146nvN2NOiPb2dioqKmhpacl0U7Jafn4+5eXlBAKBlPfxVNADbtAbY9KtoqKCoqIixo0bh9hfzf1CVamurqaiooLx48envJ8Hu7bWozemP7S0tFBWVmYh349EhLKysmP+q8lziRdBbFIzY/qJhXz/O55/Yw8GvY2jN8Z4i+cST20KBGOMx1jQG2OyQm1tLT//+c+Peb9LL72U2tra9DdoAElp1I2IXAI8DPiBX6rq/Z3WlwJPAKcBLcBXVXVzKvueaGonY43pd/f+eQtbK+vT+pqTTy7m+5+d0u36aNB/4xvfSFgeDofx+/3d7rds2bK0tbEvemtnX/SaeCLiBx4BFgGTgatFZHKnzb4NbFTV6cCXcYI91X1PqAg+u2DKmCy0dOlSPvjgA2bOnMncuXOZP38+11xzDdOmTQPg85//PLNnz2bKlCk8/vjjsf3GjRvH4cOH2bNnD5MmTeJrX/saU6ZMYcGCBTQ3N3f7fj/5yU+YPHky06dP56qrrgLg6NGjLFmyhGnTpjF9+nT+8Ic/APD0008zbdo0pk6dyre+9a3YaxQWFnLPPfdw9tlns3r1ap566inmzZvHzJkzuemmmwiHw+n5x1HVHn+AjwOvxD2/G7i70zYvAZ+Me/4BMCqVfZP9zJ49W/vLvu+frpv/9ex+e31jvGrr1q0Zff/du3frlClTVFV1xYoVGgwGddeuXbH11dXVqqra1NSkU6ZM0cOHD6uq6tixY7Wqqkp3796tfr9fN2zYoKqqX/ziF/XJJ5/s9v1Gjx6tLS0tqqpaU1Ojqqp33XWX3n777bFtjhw5ovv379cxY8booUOHtL29XefPn68vvPCCqqoC+vvf/15VnX+/yy67TNva2lRV9etf/7r+5je/Sfreyf6tgbXaTaamUsM4BdgX97zCXRZvE/AFABGZB4wFylPcF3e/G0VkrYisraqqSqFZx8fq88Z4w7x58xIuKvrJT37CjBkzOOecc9i3bx87duzoss/48eOZOXMmALNnz2bPnj3dvv706dO59tpreeqpp8jJcargr732Grfccktsm9LSUtasWcOFF17IiBEjyMnJ4dprr2XVqlUA+P1+rrjiCgBef/111q1bx9y5c5k5cyavv/46u3bt6us/A5BajT5ZMna+uPR+4GER2Qi8C2wAQinu6yxUfRx4HGDOnDn9dvGqIkTEavTGZLuCgoLY45UrV/Laa6+xevVqgsEgF154YdKLjvLy8mKP/X5/j6Wbl156iVWrVvHiiy/ygx/8gC1btqCqXca5O53t5PLz82N1eVXlK1/5Cvfdd1/Kx5iqVBKvAhgT97wcqIzfQFXrVXWJqs7EqdGPAHansu+J5oyjt169MdmmqKiIhoaGpOvq6uooLS0lGAyyfft23nzzzT69VyQSYd++fcyfP58HHniA2tpajh49yoIFC/jZz34W266mpoazzz6b//mf/+Hw4cOEw2GefvppLrjggi6vedFFF/H8889z6NAhAI4cOcLevXv71M6oVIJ+DTBRRMaLSC5wFfBi/AYiUuKuA7gBWKWq9anse6LZqBtjslNZWRnnnnsuU6dO5Zvf/GbCuksuuYRQKMT06dP53ve+xznnnNOn9wqHw1x33XVMmzaNs846izvuuIOSkhK++93vUlNTw9SpU5kxYwYrVqxg9OjR3HfffcyfP58ZM2Ywa9YsLr/88i6vOXnyZH74wx+yYMECpk+fzsUXX8yBAwf61M4o6enPithGIpcCD+EMkXxCVf9NRG4GUNXHROTjwG+BMLAVuF5Va7rbt7f3mzNnjq5du/a4Dqg3u/5lCg2BMmZ8Z1W/vL4xXrVt2zYmTZqU6WZ4QrJ/axFZp6pzkm2f0jh6VV0GLOu07LG4x6uBianum0kqdsGUMcZbPDdNsdpcN8aYY3DLLbfwxhtvJCy7/fbbWbJkSYZadOw8F/QRu8OUMeYYPPLII5luQp95rmtrPXpjjNd4rkffIIU0+Qoz3QxjjDlhPBf09+b9H4YXBTk/0w0xxpgTxHM1jAbfUBr9RZluhjEmzY53mmKAhx56iKampjS3aODwXND7RPDZuVhjss5gCvq0zUqZIs+VbhAQG0dvTP96eSkcfDe9r3nSNFjU/e0s4qcpvvjiixk5ciTPPvssra2tLF68mHvvvZfGxka+9KUvUVFRQTgc5nvf+x4fffQRlZWVzJ8/n+HDh7NixYourx0Oh7n++utZu3YtIsJXv/pV7rjjDnbu3MnNN99MVVUVfr+f5557jgkTJnDXXXfx8ssvIyJ897vf5corr2TlypXce++9jB49mo0bN/Luu++ydOlSVq5cSWtrK7fccgs33XRTev/NXJ4Lep8IPs/9HWNM9rv//vvZvHkzGzduZPny5Tz//PO8/fbbqCqf+9znWLVqFVVVVZx88sm89NJLgDMHztChQ3nwwQdZsWIFw4cPT/raGzduZP/+/WzevBkgdkeqa6+9lqVLl7J48WJaWlqIRCL88Y9/ZOPGjWzatInDhw8zd+5czj/fOSv49ttvs3nzZsaPH8/jjz/O0KFDWbNmDa2trZx77rksWLAgYcbNdPFg0Dthb4zpRz30vE+E5cuXs3z5cs466yzAuSHIjh07OO+887jzzjv51re+xWWXXcZ5552X0utNmDCBXbt2cdttt/GZz3yGBQsW0NDQwP79+1m8eDHgzEQJ8Le//Y2rr74av9/PqFGjuOCCC1izZg3FxcUJUycvX76cd955h+effx5wvnR27NhhQZ8OFvLGZD9V5e67705aClm3bh3Lli3j7rvvZsGCBdxzzz29vl5paSmbNm3ilVde4ZFHHuHZZ5/loYce6va9uxM/dbKq8tOf/pSFCxf2fkB95MkihoW9MdknfprihQsX8sQTT3D06FEA9u/fz6FDh6isrCQYDHLddddx5513sn79+i77JnP48GEikQhXXHEFP/jBD1i/fj3FxcWUl5fzpz/9CYDW1laampo4//zz+f3vf084HKaqqopVq1Yxb968Lq+5cOFCHn30Udrb2wF4//33aWxsTOc/SYwne/SW88Zkn/hpihctWsQ111zDxz/+ccC5N+tTTz3Fzp07+eY3v4nP5yMQCPDoo48CcOONN7Jo0SJGjx6d9GTs/v37WbJkCZFIBCB2c5Ann3ySm266iXvuuYdAIMBzzz3H4sWLWb16NTNmzEBEeOCBBzjppJPYvn17wmvecMMN7Nmzh1mzZqGqjBgxIvalkW4pTVN8ovXnNMWX/fR/GVmUzxP/MLdfXt8Yr7Jpik+cfpmmOJt8/YLTKcjzZ7oZxhhzwngu6D8zfXSmm2CMGcDOPvtsWltbE5Y9+eSTTJs2LUMt6jvPBb0xxvTkrbfeynQT0s6To26MMf1jIJ7zyzbH829sQW+MSYv8/Hyqq6st7PuRqlJdXR27OCtVVroxxqRFeXk5FRUVVFVVZbopWS0/P5/y8vJj2seC3hiTFoFAoF8u3zd9Z6UbY4zJchb0xhiT5SzojTEmyw3IKRBEpArYe5y7DwcOp7E5mWTHMvBky3GAHctAdbzHMlZVRyRbMSCDvi9EZG138z0MNnYsA0+2HAfYsQxU/XEsVroxxpgsZ0FvjDFZLhuD/vFMNyCN7FgGnmw5DrBjGajSfixZV6M3xhiTKBt79MYYY+JY0BtjTJbLmqAXkUtE5D0R2SkiSzPdnmMlIntE5F0R2Sgia91lw0TkVRHZ4f4uzXQ7kxGRJ0TkkIhsjlvWbdtF5G73c3pPRBZmptXJdXMs/yIi+93PZqOIXBq3biAfyxgRWSEi20Rki4jc7i4fVJ9ND8cx6D4XEckXkbdFZJN7LPe6y/v3M1HVQf8D+IEPgAlALrAJmJzpdh3jMewBhnda9gCw1H28FPj3TLezm7afD8wCNvfWdmCy+/nkAePdz82f6WPo5Vj+BbgzybYD/VhGA7Pcx0XA+26bB9Vn08NxDLrPBRCg0H0cAN4CzunvzyRbevTzgJ2quktV24BngMsz3KZ0uBz4jfv4N8DnM9eU7qnqKuBIp8Xdtf1y4BlVbVXV3cBOnM9vQOjmWLoz0I/lgKqudx83ANuAUxhkn00Px9GdAXkcAOo46j4NuD9KP38m2RL0pwD74p5X0PN/CAORAstFZJ2I3OguG6WqB8D5jx0YmbHWHbvu2j5YP6tbReQdt7QT/bN60ByLiIwDzsLpQQ7az6bTccAg/FxExC8iG4FDwKuq2u+fSbYEvSRZNtjGjZ6rqrOARcAtInJ+phvUTwbjZ/UocBowEzgA/Ke7fFAci4gUAn8A/klV63vaNMmyAXM8SY5jUH4uqhpW1ZlAOTBPRKb2sHlajiVbgr4CGBP3vByozFBbjouqVrq/DwEv4Px59pGIjAZwfx/KXAuPWXdtH3Sflap+5P7PGQF+QcefzgP+WEQkgBOOv1PVP7qLB91nk+w4BvPnAqCqtcBK4BL6+TPJlqBfA0wUkfEikgtcBbyY4TalTEQKRKQo+hhYAGzGOYavuJt9Bfh/mWnhcemu7S8CV4lInoiMByYCb2egfSmL/g/oWozz2cAAPxYREeBXwDZVfTBu1aD6bLo7jsH4uYjICBEpcR8PAT4NbKe/P5NMn4VO49nsS3HOxn8AfCfT7TnGtk/AObO+CdgSbT9QBrwO7HB/D8t0W7tp/9M4fzq34/RAru+p7cB33M/pPWBRptufwrE8CbwLvOP+jzd6kBzLJ3H+zH8H2Oj+XDrYPpsejmPQfS7AdGCD2+bNwD3u8n79TGwKBGOMyXLZUroxxhjTDQt6Y4zJchb0xhiT5SzojTEmy1nQG2NMlrOgN8aYLGdBb4wxWe7/A1YLr2TSL8gZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 최적의 에포크 위치 확인하기 : 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_score, label=\"train_score\")\n",
    "plt.plot(test_score, label=\"test_score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c61f1e-5b6a-421f-b900-20063b8f2a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 최근접 이웃(분류)\n",
    "##### - 최적의 n_neighbors 값 확인필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31eb6f36-03ab-4d35-9ddd-7de8747af64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련정확도= 0.9835680751173709\n",
      "테스트정확도= 0.958041958041958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "kn.fit(train_scaled, train_target)\n",
    "\n",
    "print(\"훈련정확도=\", kn.score(train_scaled, train_target))\n",
    "\n",
    "print(\"테스트정확도=\", kn.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec3bb0-d3a6-4172-a8cb-e3e35f623421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "17325c10-7a33-461d-89b1-247e8b4ece6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(143, 30)\n",
      "(426,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# 종속변수 독립변수 분리\n",
    "data = df.iloc[:,1:].to_numpy()\n",
    "target = df['target'].to_numpy()\n",
    "\n",
    "# 훈련/테스트 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data, target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aaf19588-3aab-4857-b74d-f4a425b91593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9577291381668946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(rf, train_input, train_target,\n",
    "                       return_train_score=True, n_jobs = -1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "43d0fdba-32a1-4f8b-9eaf-a6a60f634e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03971058 0.01460399 0.05314639 0.04277978 0.00816485 0.01140166\n",
      " 0.08321459 0.0902992  0.00443533 0.00443395 0.01951684 0.00459978\n",
      " 0.00868228 0.04355077 0.00464415 0.0036549  0.00701442 0.00504716\n",
      " 0.00371411 0.00658253 0.08127686 0.01649014 0.07138828 0.12319232\n",
      " 0.01033481 0.01580059 0.03174022 0.17229521 0.01310266 0.00518165]\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "rf.fit(train_input, train_target)\n",
    "\n",
    "# 특성 중요도 조회하기\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a883893f-c10f-4678-9668-46fde85b3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.172295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.123192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.090299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.083215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.081277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  importances\n",
       "27  worst concave points     0.172295\n",
       "23            worst area     0.123192\n",
       "7    mean concave points     0.090299\n",
       "6         mean concavity     0.083215\n",
       "20          worst radius     0.081277"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnames = pd.DataFrame(breast_cancer_data['feature_names'])\n",
    "list = rf.feature_importances_\n",
    "df_list = pd.DataFrame(list)\n",
    "df_concat = pd.concat([df_fnames, df_list], axis=1)\n",
    "# np.sort(list)[::-1]\n",
    "df_concat.columns=['name', 'importances']\n",
    "df_concat.sort_values('importances', ascending=False).head(5)\n",
    "# df_concat.sort_values('importances', ascending=False).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8e329d34-6f75-48a8-9324-29ba0ffcff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 6)\n",
      "(143, 6)\n",
      "(426,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# 독립변수 선택하기\n",
    "data = df[['worst concave points', 'worst area', 'mean concave points', 'texture error', 'mean symmetry', 'mean fractal dimension']].to_numpy()\n",
    "target = df['target'].to_numpy()\n",
    "\n",
    "# 훈련/테스트 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data, target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9c2f776e-c8a7-4073-a8d1-ce384dfa726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9436114911080711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(rf, train_input, train_target,\n",
    "                       return_train_score=True, n_jobs = -1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff819-2615-485c-a39e-450a1b7cb127",
   "metadata": {},
   "source": [
    "## 엑스트라 트리(Extra Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86c7c42c-9e4e-4b2c-8dca-3796c679bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9623803009575924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_jobs=1, random_state=42)\n",
    "scores = cross_validate(etc, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "scores\n",
    "print(scores[\"train_score\"].mean(), scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67caf3a2-2f8a-41d6-8b2e-15e1a2b131dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06526478 0.02263436 0.04037335 0.04137443 0.01127867 0.03141925\n",
      " 0.06792653 0.07436193 0.00680299 0.00864427 0.01592531 0.00632018\n",
      " 0.01699375 0.0355914  0.00717712 0.0077469  0.00781951 0.01101074\n",
      " 0.00687928 0.00718805 0.10172404 0.02771603 0.10386939 0.06440105\n",
      " 0.01958991 0.02389705 0.05887149 0.08507095 0.01407766 0.00804961]\n"
     ]
    }
   ],
   "source": [
    "etc.fit(train_input, train_target)\n",
    "print(etc.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdf42a-f5e7-4cfb-8376-dcda5e8919ee",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b77c66c8-6ceb-4366-bc73-a489b025df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9506703146374831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "scores\n",
    "print(scores[\"train_score\"].mean(), scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4ac3c2d-c406-4c37-90a7-0de79b271c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.86833960e-04 2.15961763e-02 5.42802085e-04 4.71132208e-05\n",
      " 1.47023648e-04 4.08945086e-03 2.87739793e-05 4.74446423e-01\n",
      " 4.80869688e-04 1.52187815e-04 6.86736592e-03 6.94963601e-03\n",
      " 5.82945151e-04 8.03897009e-03 7.26816483e-04 2.10782374e-03\n",
      " 1.28862568e-02 9.61166277e-03 7.87058692e-04 1.98199901e-03\n",
      " 6.56563387e-02 4.86313930e-02 3.03435540e-02 4.38122164e-02\n",
      " 4.09784590e-03 6.68395712e-04 1.65128368e-02 2.35176733e-01\n",
      " 2.15223505e-03 9.02615208e-05]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf1436-3d7b-4c5e-824a-3712e69f6f2e",
   "metadata": {},
   "source": [
    "## 히스토그램 그레디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "600447d1-f6fe-4392-b2a8-37231dd06ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9600820793433653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(hgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(scores[\"train_score\"].mean(), scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617fa6c-f490-448b-b6ed-5659240d0934",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3daeedef-9f94-4485-b980-b79de42b86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9577017783857729\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"hist\", random_state=42)\n",
    "\n",
    "scores = cross_validate(xgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(scores[\"train_score\"].mean(), scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585d99b-8647-4d34-a825-111f315f3e4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56ef4c1e-438e-4099-8ef7-f33f1c9f12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9577017783857729\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lc = LGBMClassifier()\n",
    "\n",
    "scores = cross_validate(xgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(scores[\"train_score\"].mean(), scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea34e8bb-b303-4801-82e4-dc94016092b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 결과 (독립변수 29개)\n",
    "# 1. 로지스틱 \n",
    "# 정확도 =  0.9859154929577465\n",
    "# 2. 결정트리\n",
    "# 훈련정확도= 0.9976525821596244\n",
    "# 테스트정확도= 0.951048951048951\n",
    "# 3. 경사하강법\n",
    "# 훈련정확도 =  0.9882629107981221\n",
    "# 테스트정확도 =  0.965034965034965\n",
    "# 4. KNN\n",
    "# 훈련정확도= 0.9835680751173709\n",
    "# 테스트정확도= 0.958041958041958\n",
    "# 5. RF\n",
    "# 1.0 0.9577291381668946\n",
    "# 6. 엑스트라 트리(Extra Tree)\n",
    "# 1.0 0.9623803009575924\n",
    "# 7. Gradient Boosting\n",
    "# 1.0 0.9506703146374831\n",
    "# 8. 히스토그램 그레디언트 부스팅\n",
    "# 1.0 0.9600820793433653\n",
    "# 9. XGBoost\n",
    "# 1.0 0.9577017783857729\n",
    "# 10. LightGBM\n",
    "# 1.0 0.9577017783857729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055518b-b05f-444a-83b7-468debed858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 선택 모델 : 경사하강법\n",
    "# - 훈련정확도와 테스트 정확도의 격차가 가장 적으며(일반화가 잘된 모델로 생각)\n",
    "# - 테스트 정확도가 0.965로 비교적 높은 편이라고 생각하므로\n",
    "# - 경사하강법을 선택\n",
    "# - 경사하강법의 최적의 epoch를 선택하기 위해 그래프 시각화를 진행\n",
    "# - 최적의 max_iter = 100으로 선택\n",
    "# 선택한 경사하강법의 최종 적확도는\n",
    "# 훈련정확도 =  0.9882629107981221\n",
    "# 테스트정확도 =  0.965034965034965 입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
