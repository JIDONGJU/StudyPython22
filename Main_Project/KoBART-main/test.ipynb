{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to c:\\users\\user\\appdata\\local\\temp\\pip-install-rwspc7fm\\kobart_2aa66e99ef664a81aa00a96894a88fa5\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 30c5eb7b593828d6ec2d767eeedb2f2ed02c5c2a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.24.87-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kobart) (1.4.2)\n",
      "Collecting pytorch-lightning==1.2.1\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKT-AI/KoBART 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-rwspc7fm\\kobart_2aa66e99ef664a81aa00a96894a88fa5'\n",
      "ERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from kobart) (from versions: 1.11.0, 1.12.0, 1.12.1)\n",
      "ERROR: No matching distribution found for torch==1.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached boto3-1.24.87-py3-none-any.whl (132 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 79.6/79.6 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.87\n",
      "  Downloading botocore-1.27.87-py3-none-any.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.87->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.24.87 botocore-1.27.87 jmespath-1.0.1 s3transfer-0.6.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.9.0\n",
      "  Using cached huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.7/267.7 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Installing collected packages: tokenizers, typing-extensions, tqdm, regex, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.10.0 pyyaml-6.0 regex-2022.9.13 tokenizers-0.12.1 tqdm-4.64.1 transformers-4.22.2 typing-extensions-4.3.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁안녕하', '세요.', '▁한국어', '▁B', 'A', 'R', 'T', '▁입', '니다.', '🤣', ':)', 'l^o']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "kobart_tokenizer.tokenize(\"안녕하세요. 한국어 BART 입니다.🤣:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp310-cp310-win_amd64.whl (162.2 MB)\n",
      "     -------------------------------------- 162.2/162.2 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nBartModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\test.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobart\u001b[39;00m \u001b[39mimport\u001b[39;00m get_pytorch_kobart_model, get_kobart_tokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m kobart_tokenizer \u001b[39m=\u001b[39m get_kobart_tokenizer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m BartModel\u001b[39m.\u001b[39;49mfrom_pretrained(get_pytorch_kobart_model())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m inputs \u001b[39m=\u001b[39m kobart_tokenizer([\u001b[39m'\u001b[39m\u001b[39m안녕하세요.\u001b[39m\u001b[39m'\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:947\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mcls\u001b[39m, key)\n\u001b[1;32m--> 947\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:935\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    933\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nBartModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartModel\n",
    "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "inputs = kobart_tokenizer(['안녕하세요.'], return_tensors='pt')\n",
    "model(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. ainize/kobart-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (904393792.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install transformers\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 먼저 hunggingface의 transformers 라이브러리 설치\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 302/302 [00:00<00:00, 101kB/s]\n",
      "Downloading: 100%|██████████| 682k/682k [00:01<00:00, 557kB/s]  \n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 79.9kB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\test.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#  Load Model and Tokenize\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m PreTrainedTokenizerFast\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mainize/kobart-news\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m BartForConditionalGeneration\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mainize/kobart-news\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m## 요약하고자 하는 내용을 입력\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Encode Input Text\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\u001b[39m태풍으로 물이 급격히 불어나면서 지하주차장이 침수돼 9명의 실종자를 낸 경북 포항 아파트 침수 사고.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m이틀간 진행된 배수 작업과 수색 작업이 사실상 마무리됐습니다.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m60여 명의 전담팀을 꾸린 경찰은 아파트 관리 사무소 관계자와 목격자 등을 상대로 탐문 수사를 벌이고, 국립과학수사원과 함께 현장 감식도 진행하며 사고 원인을 찾을 계획입니다.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m'''\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:947\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mcls\u001b[39m, key)\n\u001b[1;32m--> 947\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:935\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    933\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "## 모델과 문장 분리를 위한 토크나이저 불러오기\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "#  Load Model and Tokenize\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"ainize/kobart-news\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"ainize/kobart-news\")\n",
    "\n",
    "## 요약하고자 하는 내용을 입력\n",
    "# Encode Input Text\n",
    "input_text = '''태풍으로 물이 급격히 불어나면서 지하주차장이 침수돼 9명의 실종자를 낸 경북 포항 아파트 침수 사고.\n",
    "\n",
    "이틀간 진행된 배수 작업과 수색 작업이 사실상 마무리됐습니다.\n",
    "\n",
    "소방당국이 모두 8차례 인명 수색을 진행한 가운데 어제 오전 이후 생존자와 사망자는 추가로 나오지 않았습니다.\n",
    "\n",
    "지금까지 구조된 생존자는 30대 남성과 50대 여성 2명입니다.\n",
    "\n",
    "이들 모두 천장과 배관 사이, 30센티미터가 채 되지 않은 좁은 공간에서 약간의 공기층을 찾아 13시간 이상을 견디다 극적으로 구조됐습니다.\n",
    "\n",
    "하지만 이후 발견된 7명은 모두 심정지 상태로 구조됐고, 끝내 숨졌습니다.\n",
    "\n",
    "특히 마지막에 발견된 70대 남성을 제외하고는 모두 차 밖에 있었고, 대부분은 주차장 입구나 지상 연결 계단 근처에서 발견돼, 안타까움을 더했습니다.\n",
    "\n",
    "소방 당국은 물이 찰 때 엄청난 속도로 불어나며 출입구가 막히는 등 한정된 공간에서 탈출하는 게 매우 어려웠을 것이라고 설명했습니다.\n",
    "\n",
    "수색 작업이 마무리된 가운데 사고 원인 규명 작업이 본격화합니다.\n",
    "\n",
    "60여 명의 전담팀을 꾸린 경찰은 아파트 관리 사무소 관계자와 목격자 등을 상대로 탐문 수사를 벌이고, 국립과학수사원과 함께 현장 감식도 진행하며 사고 원인을 찾을 계획입니다.\n",
    "'''\n",
    "\n",
    "## 토크나이저를 사용하여 뉴스기사 원문을 모델이 인식할 수 있는 토큰형태로 바꿈\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "## \n",
    "# Generate Summary Text Ids\n",
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=0.5,                      # 길이에 대한 penalty, 1보다 작은 경우 더 짧은 문장을 생성하도록 유도\n",
    "    max_length=120,                          # 요약문의 최대 길이 설정\n",
    "    min_length=100,                           # 요약문의 최소 길이 설정\n",
    "    num_beams=4,                             # 문장 생성시 다음 단어를 탐색하는 영역의 개수\n",
    ")\n",
    "\n",
    "## 요약결과\n",
    "# Decoding Text\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. gogamza/kobart-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 4.00/4.00 [00:00<00:00, 1.00kB/s]\n",
      "Downloading: 100%|██████████| 111/111 [00:00<00:00, 27.8kB/s]\n",
      "Downloading: 100%|██████████| 682k/682k [00:01<00:00, 517kB/s]  \n",
      "Downloading: 100%|██████████| 1.18k/1.18k [00:00<00:00, 295kB/s]\n",
      "Downloading: 100%|██████████| 496M/496M [01:54<00:00, 4.33MB/s] \n"
     ]
    }
   ],
   "source": [
    "# 모델과 문장 분리를 위한 토크나이저를 불러옵니다.\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"gogamza/kobart-summarization\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약하고자 하는 기사를 입력합니다.\n",
    "# 기사원문: http://news.heraldcorp.com/view.php?ud=20211127000015\n",
    "news_text = \"세계가 ‘오미크론(Omicron)’ 공포에 빠졌다. 코로나19 델타변이도 잡지 못해 전전긍긍하는데 세계보건기구(WHO)가 또 다른 ‘우려 변이(variant of concern)’로 오미크론을 지정하면서다. 항체를 무력화 수 있는 돌연변이가 많은 걸로 파악되는 오미크론이 코로나19 백신엔 어떤 영향을 미칠지를 보려면 추가 연구가 필요한 상황이다. 각 국은 서둘러 국경의 빗장을 걸고 있다. 미국과 유럽 등 글로벌 증시를 폭락시킨 오미크론은 현재로선 어디로 튈지 모르는 변이여서 두려움을 더하고 있다.\"\n",
    "\n",
    "# 토크나이저를 사용하여 뉴스기사 원문을 모델이 인식할 수 있는 토큰형태로 바꿔줍니다.\n",
    "input_ids = tokenizer.encode(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28589, 14143, 11841, 10746, 13090, 10341, 23601, 308, 16968, 313, 14889, 28102, 19023, 11786, 14621, 24002, 14469, 10338, 9495, 15874, 25863, 13123, 10869, 25933, 23905, 17551, 14038, 12126, 9246, 9246, 16144, 14370, 20126, 17842, 19995, 271, 278, 15092, 14153, 14355, 14143, 11911, 10313, 14296, 12034, 239, 317, 15562, 304, 15195, 315, 19524, 16637, 14889, 298, 14879, 309, 240, 18407, 14075, 10746, 13090, 16298, 16241, 14457, 14130, 14577, 16428, 23582, 13714, 14032, 14082, 14327, 11806, 10869, 15028, 14467, 26185, 15920, 14343, 14075, 10746, 13090, 20983, 14469, 10338, 9495, 15874, 14566, 11467, 11788, 14593, 15587, 20667, 14404, 14046, 16939, 14927, 14541, 8981, 15490, 14431, 16247, 14319, 14071, 12005, 23987, 14071, 21521, 19238, 14324, 23153, 15964, 19593, 15251, 14048, 15365, 14258, 16632, 14556, 10214, 16366, 14075, 10746, 13090, 22686, 14475, 10338, 11268, 26531, 1700, 13312, 12332, 17989, 14296, 12034, 19266, 18018, 15065, 14166, 14058, 15964]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 모델에 넣기 전 문장의 시작과 끝을 나타내는 토큰을 추가합니다.\n",
    "input_ids = [tokenizer.bos_token_id] + input_ids + [tokenizer.eos_token_id]\n",
    "input_ids = torch.tensor([input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=2.0, # 길이에 대한 penalty값. 1보다 작은 경우 더 짧은 문장을 생성하도록 유도하며, 1보다 클 경우 길이가 더 긴 문장을 유도\n",
    "    max_length=128,     # 요약문의 최대 길이 설정\n",
    "    min_length=32,      # 요약문의 최소 길이 설정\n",
    "    num_beams=4,        # 문장 생성시 다음 단어를 탐색하는 영역의 개수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 14370, 20126, 17842, 19995,   271,   278, 15092, 14469, 10338,\n",
      "          9495, 15874, 25863, 13123, 10869, 15188, 23905, 17551, 14038, 12126,\n",
      "          9246,  9246, 14058, 14082, 16137, 14469, 10338,  9495, 15874, 14566,\n",
      "         11467, 14147, 14593, 15587, 20667, 14404, 14046, 16939, 14927, 14541,\n",
      "          8981, 15490, 14431, 16247,     1]])\n"
     ]
    }
   ],
   "source": [
    "print(summary_text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계보건기구(WHO)가 코로나19 델타변이를 잡지 못해 전전긍긍하고 있는 상황에서 코로나19 백신에는 어떤 영향을 미칠지를 보려면 추가 연구가 필요한 상황이다.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계보건기구(WHO)가 코로나19 델타변이를 잡지 못해 전전긍긍하고 있는 상황에서 코로나19 백신에는 어떤 영향을 미칠지에 대한 추가 연구가 필요하다.\n"
     ]
    }
   ],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=1.0, # 길이에 대한 penalty값. 1보다 작은 경우 더 짧은 문장을 생성하도록 유도하며, 1보다 클 경우 길이가 더 긴 문장을 유도\n",
    "    max_length=128,     # 요약문의 최대 길이 설정\n",
    "    min_length=32,      # 요약문의 최소 길이 설정\n",
    "    num_beams=4,        # 문장 생성시 다음 단어를 탐색하는 영역의 개수 \n",
    ")\n",
    "\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
