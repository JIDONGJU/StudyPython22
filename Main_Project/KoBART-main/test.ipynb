{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to c:\\users\\user\\appdata\\local\\temp\\pip-install-rwspc7fm\\kobart_2aa66e99ef664a81aa00a96894a88fa5\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 30c5eb7b593828d6ec2d767eeedb2f2ed02c5c2a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.24.87-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kobart) (1.4.2)\n",
      "Collecting pytorch-lightning==1.2.1\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKT-AI/KoBART 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-rwspc7fm\\kobart_2aa66e99ef664a81aa00a96894a88fa5'\n",
      "ERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from kobart) (from versions: 1.11.0, 1.12.0, 1.12.1)\n",
      "ERROR: No matching distribution found for torch==1.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached boto3-1.24.87-py3-none-any.whl (132 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 79.6/79.6 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.87\n",
      "  Downloading botocore-1.27.87-py3-none-any.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.87->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.24.87 botocore-1.27.87 jmespath-1.0.1 s3transfer-0.6.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.9.0\n",
      "  Using cached huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.7/267.7 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Installing collected packages: tokenizers, typing-extensions, tqdm, regex, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.10.0 pyyaml-6.0 regex-2022.9.13 tokenizers-0.12.1 tqdm-4.64.1 transformers-4.22.2 typing-extensions-4.3.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['â–ì•ˆë…•í•˜', 'ì„¸ìš”.', 'â–í•œêµ­ì–´', 'â–B', 'A', 'R', 'T', 'â–ì…', 'ë‹ˆë‹¤.', 'ğŸ¤£', ':)', 'l^o']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "kobart_tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ BART ì…ë‹ˆë‹¤.ğŸ¤£:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp310-cp310-win_amd64.whl (162.2 MB)\n",
      "     -------------------------------------- 162.2/162.2 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nBartModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\test.ipynb ì…€ 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobart\u001b[39;00m \u001b[39mimport\u001b[39;00m get_pytorch_kobart_model, get_kobart_tokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m kobart_tokenizer \u001b[39m=\u001b[39m get_kobart_tokenizer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m BartModel\u001b[39m.\u001b[39;49mfrom_pretrained(get_pytorch_kobart_model())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m inputs \u001b[39m=\u001b[39m kobart_tokenizer([\u001b[39m'\u001b[39m\u001b[39mì•ˆë…•í•˜ì„¸ìš”.\u001b[39m\u001b[39m'\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:947\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mcls\u001b[39m, key)\n\u001b[1;32m--> 947\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:935\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    933\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nBartModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartModel\n",
    "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "inputs = kobart_tokenizer(['ì•ˆë…•í•˜ì„¸ìš”.'], return_tensors='pt')\n",
    "model(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. ainize/kobart-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (904393792.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install transformers\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ë¨¼ì € hunggingfaceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 302/302 [00:00<00:00, 101kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682k/682k [00:01<00:00, 557kB/s]  \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 239/239 [00:00<00:00, 79.9kB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\test.ipynb ì…€ 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#  Load Model and Tokenize\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m PreTrainedTokenizerFast\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mainize/kobart-news\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m BartForConditionalGeneration\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mainize/kobart-news\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m## ìš”ì•½í•˜ê³ ì í•˜ëŠ” ë‚´ìš©ì„ ì…ë ¥\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Encode Input Text\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\u001b[39míƒœí’ìœ¼ë¡œ ë¬¼ì´ ê¸‰ê²©íˆ ë¶ˆì–´ë‚˜ë©´ì„œ ì§€í•˜ì£¼ì°¨ì¥ì´ ì¹¨ìˆ˜ë¼ 9ëª…ì˜ ì‹¤ì¢…ìë¥¼ ë‚¸ ê²½ë¶ í¬í•­ ì•„íŒŒíŠ¸ ì¹¨ìˆ˜ ì‚¬ê³ .\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mì´í‹€ê°„ ì§„í–‰ëœ ë°°ìˆ˜ ì‘ì—…ê³¼ ìˆ˜ìƒ‰ ì‘ì—…ì´ ì‚¬ì‹¤ìƒ ë§ˆë¬´ë¦¬ëìŠµë‹ˆë‹¤.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m60ì—¬ ëª…ì˜ ì „ë‹´íŒ€ì„ ê¾¸ë¦° ê²½ì°°ì€ ì•„íŒŒíŠ¸ ê´€ë¦¬ ì‚¬ë¬´ì†Œ ê´€ê³„ìì™€ ëª©ê²©ì ë“±ì„ ìƒëŒ€ë¡œ íƒë¬¸ ìˆ˜ì‚¬ë¥¼ ë²Œì´ê³ , êµ­ë¦½ê³¼í•™ìˆ˜ì‚¬ì›ê³¼ í•¨ê»˜ í˜„ì¥ ê°ì‹ë„ ì§„í–‰í•˜ë©° ì‚¬ê³  ì›ì¸ì„ ì°¾ì„ ê³„íšì…ë‹ˆë‹¤.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/STUDY/StudyPython22/Main_Project/KoBART-main/test.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m'''\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:947\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mcls\u001b[39m, key)\n\u001b[1;32m--> 947\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:935\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    933\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "## ëª¨ë¸ê³¼ ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•œ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "#  Load Model and Tokenize\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"ainize/kobart-news\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"ainize/kobart-news\")\n",
    "\n",
    "## ìš”ì•½í•˜ê³ ì í•˜ëŠ” ë‚´ìš©ì„ ì…ë ¥\n",
    "# Encode Input Text\n",
    "input_text = '''íƒœí’ìœ¼ë¡œ ë¬¼ì´ ê¸‰ê²©íˆ ë¶ˆì–´ë‚˜ë©´ì„œ ì§€í•˜ì£¼ì°¨ì¥ì´ ì¹¨ìˆ˜ë¼ 9ëª…ì˜ ì‹¤ì¢…ìë¥¼ ë‚¸ ê²½ë¶ í¬í•­ ì•„íŒŒíŠ¸ ì¹¨ìˆ˜ ì‚¬ê³ .\n",
    "\n",
    "ì´í‹€ê°„ ì§„í–‰ëœ ë°°ìˆ˜ ì‘ì—…ê³¼ ìˆ˜ìƒ‰ ì‘ì—…ì´ ì‚¬ì‹¤ìƒ ë§ˆë¬´ë¦¬ëìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì†Œë°©ë‹¹êµ­ì´ ëª¨ë‘ 8ì°¨ë¡€ ì¸ëª… ìˆ˜ìƒ‰ì„ ì§„í–‰í•œ ê°€ìš´ë° ì–´ì œ ì˜¤ì „ ì´í›„ ìƒì¡´ìì™€ ì‚¬ë§ìëŠ” ì¶”ê°€ë¡œ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ êµ¬ì¡°ëœ ìƒì¡´ìëŠ” 30ëŒ€ ë‚¨ì„±ê³¼ 50ëŒ€ ì—¬ì„± 2ëª…ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë“¤ ëª¨ë‘ ì²œì¥ê³¼ ë°°ê´€ ì‚¬ì´, 30ì„¼í‹°ë¯¸í„°ê°€ ì±„ ë˜ì§€ ì•Šì€ ì¢ì€ ê³µê°„ì—ì„œ ì•½ê°„ì˜ ê³µê¸°ì¸µì„ ì°¾ì•„ 13ì‹œê°„ ì´ìƒì„ ê²¬ë””ë‹¤ ê·¹ì ìœ¼ë¡œ êµ¬ì¡°ëìŠµë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ ì´í›„ ë°œê²¬ëœ 7ëª…ì€ ëª¨ë‘ ì‹¬ì •ì§€ ìƒíƒœë¡œ êµ¬ì¡°ëê³ , ëë‚´ ìˆ¨ì¡ŒìŠµë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹íˆ ë§ˆì§€ë§‰ì— ë°œê²¬ëœ 70ëŒ€ ë‚¨ì„±ì„ ì œì™¸í•˜ê³ ëŠ” ëª¨ë‘ ì°¨ ë°–ì— ìˆì—ˆê³ , ëŒ€ë¶€ë¶„ì€ ì£¼ì°¨ì¥ ì…êµ¬ë‚˜ ì§€ìƒ ì—°ê²° ê³„ë‹¨ ê·¼ì²˜ì—ì„œ ë°œê²¬ë¼, ì•ˆíƒ€ê¹Œì›€ì„ ë”í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì†Œë°© ë‹¹êµ­ì€ ë¬¼ì´ ì°° ë•Œ ì—„ì²­ë‚œ ì†ë„ë¡œ ë¶ˆì–´ë‚˜ë©° ì¶œì…êµ¬ê°€ ë§‰íˆëŠ” ë“± í•œì •ëœ ê³µê°„ì—ì„œ íƒˆì¶œí•˜ëŠ” ê²Œ ë§¤ìš° ì–´ë ¤ì› ì„ ê²ƒì´ë¼ê³  ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìˆ˜ìƒ‰ ì‘ì—…ì´ ë§ˆë¬´ë¦¬ëœ ê°€ìš´ë° ì‚¬ê³  ì›ì¸ ê·œëª… ì‘ì—…ì´ ë³¸ê²©í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "60ì—¬ ëª…ì˜ ì „ë‹´íŒ€ì„ ê¾¸ë¦° ê²½ì°°ì€ ì•„íŒŒíŠ¸ ê´€ë¦¬ ì‚¬ë¬´ì†Œ ê´€ê³„ìì™€ ëª©ê²©ì ë“±ì„ ìƒëŒ€ë¡œ íƒë¬¸ ìˆ˜ì‚¬ë¥¼ ë²Œì´ê³ , êµ­ë¦½ê³¼í•™ìˆ˜ì‚¬ì›ê³¼ í•¨ê»˜ í˜„ì¥ ê°ì‹ë„ ì§„í–‰í•˜ë©° ì‚¬ê³  ì›ì¸ì„ ì°¾ì„ ê³„íšì…ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "## í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ê¸°ì‚¬ ì›ë¬¸ì„ ëª¨ë¸ì´ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í† í°í˜•íƒœë¡œ ë°”ê¿ˆ\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "## \n",
    "# Generate Summary Text Ids\n",
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=0.5,                      # ê¸¸ì´ì— ëŒ€í•œ penalty, 1ë³´ë‹¤ ì‘ì€ ê²½ìš° ë” ì§§ì€ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„\n",
    "    max_length=120,                          # ìš”ì•½ë¬¸ì˜ ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "    min_length=100,                           # ìš”ì•½ë¬¸ì˜ ìµœì†Œ ê¸¸ì´ ì„¤ì •\n",
    "    num_beams=4,                             # ë¬¸ì¥ ìƒì„±ì‹œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ íƒìƒ‰í•˜ëŠ” ì˜ì—­ì˜ ê°œìˆ˜\n",
    ")\n",
    "\n",
    "## ìš”ì•½ê²°ê³¼\n",
    "# Decoding Text\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. gogamza/kobart-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.00/4.00 [00:00<00:00, 1.00kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 27.8kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682k/682k [00:01<00:00, 517kB/s]  \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.18k/1.18k [00:00<00:00, 295kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 496M/496M [01:54<00:00, 4.33MB/s] \n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ê³¼ ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•œ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"gogamza/kobart-summarization\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì•½í•˜ê³ ì í•˜ëŠ” ê¸°ì‚¬ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "# ê¸°ì‚¬ì›ë¬¸: http://news.heraldcorp.com/view.php?ud=20211127000015\n",
    "news_text = \"ì„¸ê³„ê°€ â€˜ì˜¤ë¯¸í¬ë¡ (Omicron)â€™ ê³µí¬ì— ë¹ ì¡Œë‹¤. ì½”ë¡œë‚˜19 ë¸íƒ€ë³€ì´ë„ ì¡ì§€ ëª»í•´ ì „ì „ê¸ê¸í•˜ëŠ”ë° ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ê°€ ë˜ ë‹¤ë¥¸ â€˜ìš°ë ¤ ë³€ì´(variant of concern)â€™ë¡œ ì˜¤ë¯¸í¬ë¡ ì„ ì§€ì •í•˜ë©´ì„œë‹¤. í•­ì²´ë¥¼ ë¬´ë ¥í™” ìˆ˜ ìˆëŠ” ëŒì—°ë³€ì´ê°€ ë§ì€ ê±¸ë¡œ íŒŒì•…ë˜ëŠ” ì˜¤ë¯¸í¬ë¡ ì´ ì½”ë¡œë‚˜19 ë°±ì‹ ì—” ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ë¥¼ ë³´ë ¤ë©´ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•œ ìƒí™©ì´ë‹¤. ê° êµ­ì€ ì„œë‘˜ëŸ¬ êµ­ê²½ì˜ ë¹—ì¥ì„ ê±¸ê³  ìˆë‹¤. ë¯¸êµ­ê³¼ ìœ ëŸ½ ë“± ê¸€ë¡œë²Œ ì¦ì‹œë¥¼ í­ë½ì‹œí‚¨ ì˜¤ë¯¸í¬ë¡ ì€ í˜„ì¬ë¡œì„  ì–´ë””ë¡œ íŠˆì§€ ëª¨ë¥´ëŠ” ë³€ì´ì—¬ì„œ ë‘ë ¤ì›€ì„ ë”í•˜ê³  ìˆë‹¤.\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ê¸°ì‚¬ ì›ë¬¸ì„ ëª¨ë¸ì´ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í† í°í˜•íƒœë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
    "input_ids = tokenizer.encode(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28589, 14143, 11841, 10746, 13090, 10341, 23601, 308, 16968, 313, 14889, 28102, 19023, 11786, 14621, 24002, 14469, 10338, 9495, 15874, 25863, 13123, 10869, 25933, 23905, 17551, 14038, 12126, 9246, 9246, 16144, 14370, 20126, 17842, 19995, 271, 278, 15092, 14153, 14355, 14143, 11911, 10313, 14296, 12034, 239, 317, 15562, 304, 15195, 315, 19524, 16637, 14889, 298, 14879, 309, 240, 18407, 14075, 10746, 13090, 16298, 16241, 14457, 14130, 14577, 16428, 23582, 13714, 14032, 14082, 14327, 11806, 10869, 15028, 14467, 26185, 15920, 14343, 14075, 10746, 13090, 20983, 14469, 10338, 9495, 15874, 14566, 11467, 11788, 14593, 15587, 20667, 14404, 14046, 16939, 14927, 14541, 8981, 15490, 14431, 16247, 14319, 14071, 12005, 23987, 14071, 21521, 19238, 14324, 23153, 15964, 19593, 15251, 14048, 15365, 14258, 16632, 14556, 10214, 16366, 14075, 10746, 13090, 22686, 14475, 10338, 11268, 26531, 1700, 13312, 12332, 17989, 14296, 12034, 19266, 18018, 15065, 14166, 14058, 15964]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ëª¨ë¸ì— ë„£ê¸° ì „ ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ëì„ ë‚˜íƒ€ë‚´ëŠ” í† í°ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "input_ids = [tokenizer.bos_token_id] + input_ids + [tokenizer.eos_token_id]\n",
    "input_ids = torch.tensor([input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=2.0, # ê¸¸ì´ì— ëŒ€í•œ penaltyê°’. 1ë³´ë‹¤ ì‘ì€ ê²½ìš° ë” ì§§ì€ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ë©°, 1ë³´ë‹¤ í´ ê²½ìš° ê¸¸ì´ê°€ ë” ê¸´ ë¬¸ì¥ì„ ìœ ë„\n",
    "    max_length=128,     # ìš”ì•½ë¬¸ì˜ ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "    min_length=32,      # ìš”ì•½ë¬¸ì˜ ìµœì†Œ ê¸¸ì´ ì„¤ì •\n",
    "    num_beams=4,        # ë¬¸ì¥ ìƒì„±ì‹œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ íƒìƒ‰í•˜ëŠ” ì˜ì—­ì˜ ê°œìˆ˜ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 14370, 20126, 17842, 19995,   271,   278, 15092, 14469, 10338,\n",
      "          9495, 15874, 25863, 13123, 10869, 15188, 23905, 17551, 14038, 12126,\n",
      "          9246,  9246, 14058, 14082, 16137, 14469, 10338,  9495, 15874, 14566,\n",
      "         11467, 14147, 14593, 15587, 20667, 14404, 14046, 16939, 14927, 14541,\n",
      "          8981, 15490, 14431, 16247,     1]])\n"
     ]
    }
   ],
   "source": [
    "print(summary_text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ê°€ ì½”ë¡œë‚˜19 ë¸íƒ€ë³€ì´ë¥¼ ì¡ì§€ ëª»í•´ ì „ì „ê¸ê¸í•˜ê³  ìˆëŠ” ìƒí™©ì—ì„œ ì½”ë¡œë‚˜19 ë°±ì‹ ì—ëŠ” ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ë¥¼ ë³´ë ¤ë©´ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•œ ìƒí™©ì´ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ê°€ ì½”ë¡œë‚˜19 ë¸íƒ€ë³€ì´ë¥¼ ì¡ì§€ ëª»í•´ ì „ì „ê¸ê¸í•˜ê³  ìˆëŠ” ìƒí™©ì—ì„œ ì½”ë¡œë‚˜19 ë°±ì‹ ì—ëŠ” ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•˜ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=1.0, # ê¸¸ì´ì— ëŒ€í•œ penaltyê°’. 1ë³´ë‹¤ ì‘ì€ ê²½ìš° ë” ì§§ì€ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ë©°, 1ë³´ë‹¤ í´ ê²½ìš° ê¸¸ì´ê°€ ë” ê¸´ ë¬¸ì¥ì„ ìœ ë„\n",
    "    max_length=128,     # ìš”ì•½ë¬¸ì˜ ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "    min_length=32,      # ìš”ì•½ë¬¸ì˜ ìµœì†Œ ê¸¸ì´ ì„¤ì •\n",
    "    num_beams=4,        # ë¬¸ì¥ ìƒì„±ì‹œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ íƒìƒ‰í•˜ëŠ” ì˜ì—­ì˜ ê°œìˆ˜ \n",
    ")\n",
    "\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
