{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to c:\\users\\user\\appdata\\local\\temp\\pip-install-bc5y7x5s\\kobart_1678a948dea840c5875ef412ef94e5f3\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 30c5eb7b593828d6ec2d767eeedb2f2ed02c5c2a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: boto3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kobart) (1.24.87)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kobart) (1.4.2)\n",
      "Collecting pytorch-lightning==1.2.1\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKT-AI/KoBART 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-bc5y7x5s\\kobart_1678a948dea840c5875ef412ef94e5f3'\n",
      "ERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from kobart) (from versions: 1.11.0, 1.12.0, 1.12.1)\n",
      "ERROR: No matching distribution found for torch==1.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.87)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.87 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (1.27.87)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.28.0,>=1.27.87->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.87->boto3) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁안녕하', '세요.', '▁한국어', '▁B', 'A', 'R', 'T', '▁입', '니다.', '🤣', ':)', 'l^o']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "kobart_tokenizer.tokenize(\"안녕하세요. 한국어 BART 입니다.🤣:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "c:\\STUDY\\StudyPython22\\Main_Project\\KoBART-main\\.cache\\kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:133: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  t = torch.tensor([], dtype=storage.dtype, device=storage._untyped().device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqModelOutput(last_hidden_state=tensor([[[-0.4418, -4.3673,  3.2404,  ...,  5.8832,  4.0629,  3.5540],\n",
       "         [-0.1316, -4.6446,  2.5955,  ...,  6.0093,  2.7467,  3.0007]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), past_key_values=((tensor([[[[-9.7980e-02, -6.6584e-01, -1.8089e+00,  ...,  9.6023e-01,\n",
       "           -1.8818e-01, -1.3252e+00],\n",
       "          [-6.2507e-01,  5.1009e-01, -7.4878e-01,  ...,  8.6230e-01,\n",
       "            1.5722e-01, -6.0267e-01]],\n",
       "\n",
       "         [[ 5.4597e-01, -2.3990e-01,  1.5901e+00,  ...,  4.3655e-01,\n",
       "            7.9514e-01,  8.9880e-02],\n",
       "          [-1.7327e-01, -6.3167e-01,  4.5152e-02,  ..., -1.4111e-01,\n",
       "            1.8678e-01, -1.2081e-01]],\n",
       "\n",
       "         [[ 1.4621e+00,  1.8980e+00, -7.6696e-01,  ...,  1.5695e+00,\n",
       "            6.7921e-02, -3.9372e-01],\n",
       "          [-4.1204e-02,  1.7132e+00, -1.1863e+00,  ..., -2.2272e-01,\n",
       "            9.8310e-02,  8.1729e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.8868e-01,  1.2633e+00, -1.1658e-01,  ..., -3.1989e-01,\n",
       "            1.2202e+00, -7.9021e-02],\n",
       "          [-8.4946e-01,  8.9379e-02, -1.0224e+00,  ...,  3.3125e-01,\n",
       "           -2.5262e-01,  5.0875e-01]],\n",
       "\n",
       "         [[ 1.5854e+00,  3.2461e-01,  3.0826e+00,  ..., -1.6728e+00,\n",
       "            1.2071e+00, -3.5671e-01],\n",
       "          [ 5.5400e-02, -9.2782e-01, -2.3053e-03,  ..., -6.1645e-01,\n",
       "            1.0880e+00,  2.8645e-01]],\n",
       "\n",
       "         [[ 8.7081e-01, -4.6088e-01, -2.8388e+00,  ...,  1.6038e+00,\n",
       "           -1.0963e+00, -1.8732e-01],\n",
       "          [ 4.5471e-01, -3.1087e-02, -2.4484e+00,  ...,  1.9392e+00,\n",
       "           -4.0694e-01, -1.9906e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 0.2187,  1.3322, -0.0016,  ..., -0.1200, -0.0395,  0.0971],\n",
       "          [-0.2722, -0.0590,  0.4620,  ...,  0.1822, -0.0171, -0.2176]],\n",
       "\n",
       "         [[ 0.1439,  0.0074,  0.0249,  ...,  0.2148, -0.5016,  0.1263],\n",
       "          [ 0.3625, -0.3192, -0.2254,  ...,  0.6312,  0.1061,  0.3506]],\n",
       "\n",
       "         [[-0.0862, -0.0073, -0.0479,  ...,  0.0110,  0.0198,  0.1909],\n",
       "          [-0.4622, -0.4537, -0.6060,  ...,  0.5620,  1.3319,  0.0989]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0868, -0.1329,  0.1862,  ..., -0.0489, -0.0084,  0.0151],\n",
       "          [-0.4065,  0.4082,  0.7682,  ..., -0.0909,  0.1701,  0.0145]],\n",
       "\n",
       "         [[ 0.1256,  0.1170,  0.0912,  ...,  0.0623, -0.0574,  0.0611],\n",
       "          [-0.2664, -0.4485,  0.1439,  ...,  0.2324,  0.3832, -1.0943]],\n",
       "\n",
       "         [[ 0.0702,  0.0227,  0.0311,  ..., -0.0203,  0.0602,  0.0033],\n",
       "          [-0.3197,  0.4879,  0.1972,  ..., -0.3241,  0.1762,  0.5655]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-1.0648, -2.5643, -1.2208,  ...,  1.4609,  1.0088,  0.8616],\n",
       "          [-1.3031, -2.4746, -1.2874,  ...,  1.4641,  0.6007,  0.5663]],\n",
       "\n",
       "         [[-0.9957, -1.4633, -0.6104,  ..., -0.0807,  0.6639,  1.1657],\n",
       "          [-0.8524, -2.1023, -0.3089,  ...,  0.1747,  0.9409,  0.8996]],\n",
       "\n",
       "         [[ 1.7265, -0.0293, -0.3755,  ..., -0.6951,  0.4730,  0.3141],\n",
       "          [ 1.5839, -0.6262, -0.5321,  ...,  0.2295,  0.5922,  0.6125]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1965, -0.4015,  1.1312,  ..., -0.5016, -0.1073,  0.0549],\n",
       "          [-0.5866, -0.6739,  1.0961,  ..., -0.3082, -0.1296,  0.0126]],\n",
       "\n",
       "         [[-0.0225,  0.6815, -1.6006,  ...,  1.7747, -0.4324, -1.2341],\n",
       "          [ 0.2012,  0.2133, -2.0224,  ...,  1.0445, -0.3429, -1.1153]],\n",
       "\n",
       "         [[-0.4898, -0.2916,  0.1036,  ..., -1.1657, -2.0047, -0.5035],\n",
       "          [ 0.2014,  0.0172, -0.2052,  ..., -1.1187, -2.9760, -0.2174]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.2822, -0.1429, -0.0214,  ...,  0.0815,  0.1900, -0.2706],\n",
       "          [ 0.0435, -0.3802, -0.3064,  ...,  0.5159,  0.1527, -0.2039]],\n",
       "\n",
       "         [[-0.8001,  0.0466,  1.0855,  ..., -0.2635, -0.2926,  0.3927],\n",
       "          [-0.3446, -0.6481,  0.5623,  ...,  0.3295,  0.6792,  0.4060]],\n",
       "\n",
       "         [[-0.8864, -0.0462, -0.4937,  ..., -1.2180,  0.5027,  0.1991],\n",
       "          [-0.8240, -0.4198,  0.1187,  ..., -0.3042,  0.6595, -0.1653]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3499,  0.7639,  0.0130,  ...,  0.3620,  0.4275, -0.6412],\n",
       "          [-0.1910,  0.5114, -0.0352,  ...,  0.3060,  0.2019, -0.4844]],\n",
       "\n",
       "         [[ 0.2417,  0.1567,  0.2082,  ...,  0.1640, -0.1767, -0.1738],\n",
       "          [ 0.1304, -0.0716, -0.1840,  ...,  0.3307,  0.1039,  0.1808]],\n",
       "\n",
       "         [[-0.4749, -0.9211,  1.0276,  ..., -0.3349, -0.2668, -0.2143],\n",
       "          [ 0.0051, -0.7191,  0.6315,  ..., -0.2618,  0.0611, -0.1337]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[ 0.0568,  0.1593,  0.3356,  ..., -0.0771, -0.1446, -0.1562],\n",
       "          [ 1.6254, -1.5403,  1.2852,  ...,  0.3466, -1.0204, -1.6762]],\n",
       "\n",
       "         [[ 0.2014, -0.2892, -0.4829,  ...,  0.2817, -0.1413,  1.5805],\n",
       "          [ 0.6554,  1.6124,  0.4492,  ...,  0.3675,  1.0584, -3.6320]],\n",
       "\n",
       "         [[-0.1167,  0.6492, -0.5715,  ...,  0.0990, -1.3751, -0.3157],\n",
       "          [ 0.5295, -2.8552,  1.0669,  ...,  0.8807,  2.6310, -0.9037]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0606,  0.1003,  0.1334,  ...,  0.0648,  0.0886,  1.1766],\n",
       "          [ 0.9016, -1.1139,  1.2164,  ...,  0.0885,  0.5449, -1.5874]],\n",
       "\n",
       "         [[ 0.1461,  0.1861,  0.0330,  ..., -0.0966, -0.3876,  0.2000],\n",
       "          [-0.4877,  0.6808,  0.8141,  ...,  1.1511, -1.0541, -0.7516]],\n",
       "\n",
       "         [[ 0.4198,  0.1532,  0.4183,  ..., -0.1995, -0.0194,  0.3649],\n",
       "          [ 1.9049,  0.4632, -1.9892,  ...,  0.2458,  0.5797, -0.5118]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 1.5379e-02,  4.6779e-02,  2.3209e-02,  ..., -3.6808e-03,\n",
       "           -6.6380e-02,  8.8304e-04],\n",
       "          [ 3.3722e-01,  5.9773e-01, -9.7631e-01,  ..., -6.7000e-01,\n",
       "           -8.6936e-01, -1.0744e+00]],\n",
       "\n",
       "         [[-8.2674e-03, -2.8381e-02, -3.8986e-02,  ...,  1.9672e-02,\n",
       "            2.6156e-03,  2.0188e-03],\n",
       "          [ 4.2856e-01,  1.3611e+00,  4.8732e-01,  ..., -5.9340e-02,\n",
       "           -1.1926e-01, -4.2578e-02]],\n",
       "\n",
       "         [[ 6.0655e-02, -1.8254e-02, -1.5229e-02,  ..., -1.6663e-02,\n",
       "            8.4880e-03, -4.8301e-02],\n",
       "          [-1.0497e-01, -8.1324e-02,  3.3243e-01,  ...,  3.5059e-01,\n",
       "           -7.1202e-02,  1.6473e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6912e-02, -6.7970e-02, -8.0440e-02,  ..., -9.4137e-02,\n",
       "            3.8141e-03,  7.8198e-02],\n",
       "          [-2.4057e-01,  2.6766e-03,  7.9480e-01,  ...,  2.9896e-01,\n",
       "            7.9629e-01,  9.2801e-01]],\n",
       "\n",
       "         [[ 1.9845e-02,  4.9132e-03, -3.3145e-02,  ...,  7.2793e-02,\n",
       "            5.9300e-02, -5.7760e-02],\n",
       "          [-3.6504e-01,  5.4651e-01, -4.3530e-02,  ..., -3.2015e-01,\n",
       "            7.9081e-01, -9.7559e-02]],\n",
       "\n",
       "         [[ 3.4483e-02, -1.2532e-02,  1.5040e-02,  ...,  1.7609e-02,\n",
       "           -2.3566e-02, -2.2959e-02],\n",
       "          [-1.1245e+00, -6.8236e-01,  1.0025e-01,  ..., -2.7405e-01,\n",
       "           -5.1046e-01, -1.9639e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 2.3286e+00, -4.2947e-02,  3.0110e+00,  ...,  1.0627e+00,\n",
       "           -9.1235e-01,  2.6603e+00],\n",
       "          [ 3.0073e+00, -1.5674e-01,  2.8979e+00,  ...,  9.7826e-01,\n",
       "           -5.3162e-01,  3.0233e+00]],\n",
       "\n",
       "         [[ 1.7130e+00, -2.9926e+00,  1.8776e+00,  ...,  7.5416e-01,\n",
       "           -8.7124e-01, -4.8129e-01],\n",
       "          [ 2.5120e+00, -3.2266e+00,  2.2682e+00,  ...,  4.4046e-01,\n",
       "           -5.1476e-01, -5.2341e-01]],\n",
       "\n",
       "         [[-8.1485e-01, -9.5213e-01, -8.3381e-04,  ...,  1.5024e+00,\n",
       "           -5.7569e-01,  1.9130e-01],\n",
       "          [-8.1358e-01, -1.2385e+00,  9.3572e-01,  ...,  1.1406e+00,\n",
       "           -9.5045e-01, -4.8016e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.1763e-01, -9.2276e-01,  1.5260e+00,  ...,  2.9563e-02,\n",
       "            1.5474e-02, -8.2439e-01],\n",
       "          [ 1.4519e-02, -1.5225e+00,  1.9413e+00,  ..., -3.6908e-01,\n",
       "            5.3651e-01, -2.1469e-01]],\n",
       "\n",
       "         [[-1.0017e+00, -5.5066e-01, -1.8923e+00,  ..., -5.8160e-01,\n",
       "            4.2548e-01, -6.7959e-01],\n",
       "          [-5.8291e-01, -8.2588e-01, -2.0550e+00,  ..., -2.2966e-01,\n",
       "            2.4396e-02, -2.6139e-01]],\n",
       "\n",
       "         [[-1.4829e+00, -8.8995e-01,  9.4026e-01,  ...,  1.4175e+00,\n",
       "           -3.9160e-01, -9.2237e-01],\n",
       "          [-1.0111e+00, -1.1450e+00,  1.1993e+00,  ...,  2.0617e+00,\n",
       "           -5.9144e-01, -1.3860e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 0.1935, -0.1730,  0.3934,  ..., -0.0840,  0.2339,  0.1091],\n",
       "          [-0.0569, -0.3551,  0.3823,  ...,  0.0197, -0.0043, -0.0436]],\n",
       "\n",
       "         [[ 0.2364,  0.4606,  0.5622,  ...,  0.4819,  0.1865,  0.6264],\n",
       "          [ 0.5973,  0.2811,  0.2784,  ...,  0.1489, -0.4533,  0.4468]],\n",
       "\n",
       "         [[ 0.4116,  0.4325, -0.3306,  ..., -0.7509,  0.2645, -0.1624],\n",
       "          [ 0.8045,  0.3654, -0.4785,  ..., -0.7986, -0.0484, -0.1889]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1706, -1.0074,  0.2970,  ...,  0.4921,  0.5458,  0.1225],\n",
       "          [ 0.3865, -1.1976, -0.2150,  ...,  0.6561,  0.4510,  0.1755]],\n",
       "\n",
       "         [[ 0.0047, -0.7317,  0.3213,  ...,  0.5871, -0.2654, -0.4047],\n",
       "          [-0.1921, -0.4592,  0.0943,  ...,  0.3975, -0.2417, -0.3156]],\n",
       "\n",
       "         [[-0.1002, -0.3230,  0.6674,  ..., -0.2355, -0.6963, -0.3525],\n",
       "          [-0.1739, -0.4883,  0.4101,  ..., -0.2514, -0.6257, -0.6858]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[-0.1980, -0.8728,  0.6663,  ...,  0.2215,  0.3865, -0.0239],\n",
       "          [ 0.7417,  3.5312, -0.8480,  ..., -0.0536, -0.7790, -0.2229]],\n",
       "\n",
       "         [[ 0.3768, -0.2689, -0.0428,  ...,  0.1046, -0.1428, -0.9039],\n",
       "          [ 0.0478,  2.5229, -0.2297,  ..., -0.2463,  3.8656,  4.1838]],\n",
       "\n",
       "         [[-0.0777,  0.5079,  0.0822,  ...,  0.0193, -0.5585,  0.1365],\n",
       "          [ 0.6972, -2.6046,  1.8231,  ..., -1.2138,  2.4488,  0.6540]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4664,  0.2169,  0.0277,  ...,  1.1934,  0.6856,  0.1670],\n",
       "          [ 0.6041,  0.9994,  0.1424,  ..., -1.8193, -1.1613, -0.5548]],\n",
       "\n",
       "         [[ 0.0759,  0.1255, -0.0151,  ...,  0.0307,  0.1052, -0.6455],\n",
       "          [ 0.6701,  0.7716,  0.2974,  ..., -0.7394,  0.5873,  3.0509]],\n",
       "\n",
       "         [[ 0.1543,  0.2131, -0.0718,  ...,  0.0975, -0.0069, -0.3904],\n",
       "          [-0.5077, -1.8357,  2.1244,  ...,  0.3969,  1.3626, -0.0225]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 2.9269e-02,  1.1764e-01, -1.2732e-02,  ..., -8.6455e-02,\n",
       "            1.2252e-01,  6.7036e-03],\n",
       "          [ 3.9763e-01, -2.9863e-01, -4.3627e-01,  ..., -5.6596e-02,\n",
       "           -2.9131e-01, -6.3776e-01]],\n",
       "\n",
       "         [[ 1.6335e-02, -2.4424e-02, -4.8431e-03,  ..., -5.6252e-02,\n",
       "           -6.8835e-02,  1.2608e-02],\n",
       "          [ 3.5408e-01,  6.1424e-01,  3.5653e-01,  ..., -3.0892e-02,\n",
       "            7.4475e-02,  2.0799e-02]],\n",
       "\n",
       "         [[ 2.5243e-02,  1.0407e-02, -4.8344e-02,  ...,  6.4945e-03,\n",
       "            3.9794e-04,  1.2100e-01],\n",
       "          [ 7.1725e-01, -1.8262e-01, -3.0230e-01,  ..., -4.4057e-01,\n",
       "           -3.8583e-02, -2.3157e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.2560e-03,  1.4655e-02,  3.4054e-02,  ...,  9.6428e-03,\n",
       "           -6.3913e-03,  2.7569e-02],\n",
       "          [ 4.2214e-01,  3.7137e-01,  2.3890e-01,  ..., -1.7630e-01,\n",
       "            9.0582e-01,  1.0196e-01]],\n",
       "\n",
       "         [[ 3.1056e-03,  1.0484e-02, -4.7095e-03,  ...,  4.8638e-02,\n",
       "           -1.5250e-02, -7.0406e-02],\n",
       "          [ 9.7426e-02,  2.6014e-01,  3.1176e-01,  ..., -4.8579e-01,\n",
       "            9.3071e-01, -1.1125e-01]],\n",
       "\n",
       "         [[ 2.8621e-02, -2.8968e-03, -3.1328e-02,  ...,  2.5224e-02,\n",
       "            1.8680e-02, -4.3578e-02],\n",
       "          [ 3.0150e-01, -1.9468e-01, -1.7805e-01,  ...,  5.1854e-01,\n",
       "           -3.4876e-02,  9.8427e-02]]]], grad_fn=<CloneBackward0>), tensor([[[[-1.7399,  1.5544,  0.8420,  ...,  0.1949,  0.3739, -0.4898],\n",
       "          [-1.6240,  1.3219,  0.9978,  ..., -0.4160, -0.1783,  0.3793]],\n",
       "\n",
       "         [[-0.2877, -0.3362, -0.3745,  ...,  0.3365,  0.1496, -1.2037],\n",
       "          [-0.2730, -0.1071, -0.1413,  ...,  0.3996, -0.1407, -1.1605]],\n",
       "\n",
       "         [[ 1.4108, -0.6566,  1.7061,  ...,  1.4992,  0.5674, -0.9317],\n",
       "          [ 1.7853, -1.0445,  1.7326,  ...,  1.7643,  0.5169, -1.0316]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7319,  3.2136,  1.1013,  ..., -0.8693, -0.2972, -1.2679],\n",
       "          [-2.0636,  3.6187,  0.9261,  ..., -0.9856, -0.3694, -1.0883]],\n",
       "\n",
       "         [[-0.9236,  0.7800, -0.0765,  ...,  1.6758,  1.2948,  0.3508],\n",
       "          [-0.6022,  0.7458, -0.1418,  ...,  2.1779,  1.1909,  0.1315]],\n",
       "\n",
       "         [[ 0.4240,  0.0391, -1.3894,  ..., -1.0823, -0.4126,  0.9783],\n",
       "          [ 0.5731, -0.2723, -1.8803,  ..., -1.2079, -1.0119,  0.5113]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.0985, -0.6352, -0.0868,  ...,  0.0363,  0.0543, -0.3238],\n",
       "          [-0.2378, -0.1665, -0.3516,  ...,  0.3921, -0.2744, -0.3039]],\n",
       "\n",
       "         [[ 0.8450,  0.2317,  0.6335,  ...,  0.5318, -0.0949,  0.1750],\n",
       "          [ 0.5121,  0.0876,  0.5792,  ..., -0.0148, -0.4605,  0.2020]],\n",
       "\n",
       "         [[-0.2443, -0.0378,  0.2317,  ...,  0.0219, -0.1216,  0.0395],\n",
       "          [-0.4156,  0.0576,  0.1678,  ...,  0.0501, -0.3476, -0.2093]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1073,  0.2830,  0.1495,  ..., -1.0262,  0.5416,  0.5043],\n",
       "          [ 0.2258,  0.0643, -0.1481,  ..., -1.0380,  0.3420,  0.5458]],\n",
       "\n",
       "         [[-0.1796, -0.4815,  0.2412,  ..., -0.1130,  0.5764,  0.0777],\n",
       "          [-0.2803, -0.4700,  0.0848,  ...,  0.2658,  0.4753,  0.1039]],\n",
       "\n",
       "         [[ 0.5494,  0.6024, -0.6296,  ...,  0.1007,  0.8262, -0.1736],\n",
       "          [ 0.3254,  0.5532, -0.1605,  ..., -0.2396,  0.2754,  0.1460]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[ 0.8659,  1.2230, -0.0036,  ..., -0.1768,  1.2656,  1.3975],\n",
       "          [-2.4391, -1.6445,  1.7410,  ..., -1.8302, -2.0103, -1.7548]],\n",
       "\n",
       "         [[ 0.4183,  0.5536,  0.7881,  ..., -0.2234,  0.4811, -0.0375],\n",
       "          [-1.6890, -0.3787, -1.0577,  ..., -0.8861, -1.5151, -0.2258]],\n",
       "\n",
       "         [[-0.5553, -1.0096,  0.1065,  ..., -0.4831,  1.4737, -0.0735],\n",
       "          [ 0.7138,  0.3943,  0.3157,  ...,  0.2931, -0.2829,  0.3843]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6875,  0.4129, -0.7369,  ..., -1.1018, -0.7937,  0.5081],\n",
       "          [ 1.8270,  0.4463, -1.1159,  ...,  0.7450,  1.0975,  0.1329]],\n",
       "\n",
       "         [[ 0.2528,  0.2051,  0.2412,  ...,  0.1542,  0.5065, -0.0168],\n",
       "          [ 0.0560,  1.4332,  0.3786,  ...,  0.1777, -0.5803,  0.0421]],\n",
       "\n",
       "         [[-0.2057,  0.4577,  0.8795,  ..., -0.3249, -0.0460,  0.9419],\n",
       "          [-1.3328,  0.4214, -0.5938,  ..., -0.5810,  0.0759, -0.4099]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-4.0518e-02, -5.9251e-02, -1.6183e-02,  ..., -8.3803e-04,\n",
       "           -3.3078e-02,  7.6100e-02],\n",
       "          [-4.3446e-01, -1.9747e-01, -4.3507e-01,  ..., -4.8681e-01,\n",
       "           -2.7235e-01, -8.4324e-02]],\n",
       "\n",
       "         [[-1.4299e-01,  1.0976e-01, -3.2061e-02,  ..., -7.9137e-02,\n",
       "           -6.2019e-02,  1.1654e-03],\n",
       "          [ 5.5592e-01, -4.1030e-02,  1.5684e-01,  ...,  4.7759e-01,\n",
       "            4.6287e-01,  1.3250e-01]],\n",
       "\n",
       "         [[-1.0311e-02, -3.4038e-02, -1.5415e-01,  ...,  2.3261e-02,\n",
       "           -1.4703e-02,  2.4091e-02],\n",
       "          [-8.1498e-01, -3.5524e-01,  3.3232e-02,  ...,  2.5945e-01,\n",
       "            5.5899e-02,  1.0831e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8605e-02,  5.5119e-02,  2.7359e-03,  ..., -2.4560e-02,\n",
       "            6.2882e-03,  5.5262e-03],\n",
       "          [ 1.2290e-01, -4.1711e-01, -3.5410e-02,  ..., -2.1633e-01,\n",
       "           -4.8053e-01,  9.0853e-02]],\n",
       "\n",
       "         [[-8.3876e-04,  6.2181e-02, -3.9761e-02,  ...,  5.1470e-02,\n",
       "            7.0819e-02,  8.0597e-03],\n",
       "          [ 5.9446e-02,  5.7503e-01, -7.6640e-01,  ...,  4.2504e-03,\n",
       "           -7.7811e-02,  9.4071e-02]],\n",
       "\n",
       "         [[ 7.7253e-02,  7.0009e-02, -1.6194e-02,  ...,  2.5476e-02,\n",
       "           -8.1933e-03,  2.2595e-02],\n",
       "          [ 1.1499e-01, -3.9242e-01,  7.6922e-01,  ...,  2.9297e-01,\n",
       "            8.2074e-01,  6.4680e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 2.0849, -0.0636,  0.5000,  ...,  0.9966,  1.7627,  1.5514],\n",
       "          [ 1.7876, -0.7635,  1.6988,  ...,  2.0722,  1.4739,  1.1660]],\n",
       "\n",
       "         [[-0.8371,  0.9337,  0.7837,  ...,  0.0498,  1.6516,  0.1707],\n",
       "          [-0.5368,  1.0880,  0.5653,  ..., -0.0634,  1.3486, -0.6582]],\n",
       "\n",
       "         [[-0.0912,  0.6096, -0.6076,  ...,  0.7558, -0.0126, -1.5131],\n",
       "          [-0.2230,  0.5867, -0.7267,  ...,  0.8867, -0.1216, -1.8096]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6766,  0.6220,  1.5134,  ..., -0.1829,  0.0215,  1.1120],\n",
       "          [-0.8275,  0.6928,  1.6118,  ..., -0.2364,  0.0025,  1.4436]],\n",
       "\n",
       "         [[ 1.1364,  0.0790, -0.3696,  ...,  0.2541,  0.9125, -0.5037],\n",
       "          [ 1.5442,  0.0934, -0.4613,  ...,  0.0754,  0.0034, -0.9217]],\n",
       "\n",
       "         [[ 1.2640, -0.4548, -0.5475,  ...,  0.5674, -0.4214, -1.0081],\n",
       "          [ 1.2149, -0.7560, -0.2841,  ...,  0.4172, -0.3426, -0.9019]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.0386, -0.1903,  0.1470,  ..., -0.3462, -0.1094, -0.1254],\n",
       "          [-0.0886,  0.0395,  0.0272,  ...,  0.0271, -0.3885,  0.0461]],\n",
       "\n",
       "         [[ 0.1720, -0.3733, -0.0356,  ...,  0.0848,  0.4297,  0.5137],\n",
       "          [ 0.2865, -0.2505, -0.2307,  ..., -0.2456,  0.3889,  0.3922]],\n",
       "\n",
       "         [[-0.5288, -0.7187,  0.3537,  ..., -0.7664,  0.2124,  0.3075],\n",
       "          [-0.3642, -0.0657,  0.0399,  ..., -0.5451,  0.2110,  0.1761]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1834, -0.7011,  0.8361,  ...,  0.3994, -0.3654, -0.3145],\n",
       "          [ 0.2181, -0.7129,  0.8148,  ...,  0.1566,  0.0218,  0.0515]],\n",
       "\n",
       "         [[-0.3867, -0.7703, -0.4015,  ..., -0.3819, -0.8259,  0.0101],\n",
       "          [ 0.2124,  0.1236, -0.8350,  ...,  0.3556, -1.1067, -0.0330]],\n",
       "\n",
       "         [[-0.1518, -0.0204,  0.3507,  ..., -0.0252, -0.2174,  0.3534],\n",
       "          [ 0.2348, -0.1401,  0.4585,  ...,  0.2866, -0.0423,  0.0067]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[-0.2997,  1.0674, -0.2439,  ..., -0.2289, -0.6333, -0.6078],\n",
       "          [ 0.9438, -1.8757, -0.5755,  ...,  0.1229,  1.7929, -0.3130]],\n",
       "\n",
       "         [[ 0.3514,  1.5137,  0.4524,  ...,  1.1948, -1.3977,  0.3308],\n",
       "          [ 0.1387, -1.1616, -0.6226,  ..., -2.1536, -0.1766, -1.1653]],\n",
       "\n",
       "         [[-1.3330, -0.6003,  0.2709,  ...,  1.1001, -0.1418, -0.6230],\n",
       "          [-1.5638,  1.9531, -0.2184,  ..., -0.3042, -2.2814,  1.5291]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4103, -0.2594, -0.7356,  ...,  0.4831,  0.0690,  0.3132],\n",
       "          [-0.5332,  0.1774,  1.8028,  ...,  0.1322,  0.1915, -0.9951]],\n",
       "\n",
       "         [[-0.0831, -0.3862, -0.7452,  ..., -0.2725, -0.0534, -0.2660],\n",
       "          [-1.4382, -1.8134,  2.8000,  ..., -0.8421, -0.6358,  0.1198]],\n",
       "\n",
       "         [[-1.0351, -0.4564, -1.0894,  ...,  0.2800, -0.1461, -0.3104],\n",
       "          [ 0.2128, -0.7712, -0.1874,  ..., -0.7119, -0.5132, -1.6355]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-3.3177e-02, -1.8023e-04,  4.5824e-04,  ...,  1.3248e-02,\n",
       "            1.9023e-02,  3.2562e-02],\n",
       "          [-3.2167e-02, -1.5418e-01,  1.4814e-01,  ..., -2.6376e-01,\n",
       "            1.0806e-02, -6.4121e-01]],\n",
       "\n",
       "         [[-1.0983e-02, -2.1240e-02, -4.1562e-02,  ..., -2.0584e-02,\n",
       "           -5.9072e-02, -6.3754e-02],\n",
       "          [-7.4979e-01,  4.7896e-01,  3.1803e-01,  ..., -2.9700e-01,\n",
       "           -1.4955e-01, -2.6639e-01]],\n",
       "\n",
       "         [[ 5.7588e-02,  8.7107e-02, -3.4391e-02,  ..., -1.3255e-02,\n",
       "            2.8237e-02,  1.2374e-01],\n",
       "          [-6.9403e-01,  5.8305e-01, -4.0449e-03,  ...,  2.2896e-02,\n",
       "           -6.2816e-01,  3.7408e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4895e-02,  7.3232e-03,  3.9967e-02,  ...,  4.8722e-02,\n",
       "           -6.5669e-02, -5.9926e-02],\n",
       "          [-1.0827e+00, -5.7699e-01,  4.4333e-01,  ...,  2.7596e-01,\n",
       "            9.1006e-01, -4.2224e-01]],\n",
       "\n",
       "         [[-2.7116e-02,  1.4112e-02, -1.0806e-01,  ..., -2.1597e-02,\n",
       "            1.6286e-02,  6.7959e-03],\n",
       "          [ 2.9614e-01,  6.9683e-01,  2.1899e-01,  ...,  1.0726e-02,\n",
       "            3.8513e-02,  1.0382e-02]],\n",
       "\n",
       "         [[ 5.4609e-03,  4.4768e-02, -1.2635e-02,  ...,  1.2817e-03,\n",
       "            3.0699e-02, -1.0643e-01],\n",
       "          [-3.3885e-01, -4.5146e-02,  4.8048e-02,  ..., -4.6988e-01,\n",
       "            2.6005e-01, -7.2162e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 1.0374,  0.3910, -0.6754,  ...,  0.2131, -0.7792,  0.1073],\n",
       "          [ 0.6857,  0.6310, -0.8816,  ..., -0.0665,  0.0525, -0.0755]],\n",
       "\n",
       "         [[ 0.5946, -0.2358, -1.0037,  ..., -0.7404, -1.1777, -2.7705],\n",
       "          [ 0.9685, -0.8442, -1.0034,  ..., -0.5312, -1.2558, -2.5045]],\n",
       "\n",
       "         [[-0.8795, -0.7718, -1.1451,  ...,  0.3562,  0.6508, -0.3904],\n",
       "          [-0.6928, -1.3858, -1.1689,  ...,  0.9893,  0.1329, -0.7229]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6684, -0.8720,  0.7093,  ...,  1.3669,  1.9079,  0.6156],\n",
       "          [-3.0017, -0.5989,  0.8993,  ...,  1.0432,  1.9339, -0.0553]],\n",
       "\n",
       "         [[-3.6058,  2.1486,  2.1966,  ...,  1.6173, -2.3318, -0.6465],\n",
       "          [-3.9024,  2.2764,  2.3965,  ...,  0.1705, -2.1405, -0.2133]],\n",
       "\n",
       "         [[-0.7480,  1.9170,  1.3470,  ...,  0.4011, -0.4394, -1.1463],\n",
       "          [-0.3069,  1.8317,  1.8609,  ...,  0.0209, -0.2684, -0.9492]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.7396, -0.1129,  0.1192,  ..., -0.0200, -0.2694, -0.1733],\n",
       "          [ 0.9639, -0.3486, -0.0451,  ..., -0.7172, -0.3156,  0.1609]],\n",
       "\n",
       "         [[ 0.0073, -0.7114, -0.4992,  ..., -0.3623, -0.2582,  0.3008],\n",
       "          [ 0.2753, -0.3529, -0.4996,  ..., -0.3469, -0.0021,  0.2831]],\n",
       "\n",
       "         [[ 0.1104,  0.1524, -0.2274,  ..., -0.2116,  0.0372,  0.3177],\n",
       "          [ 0.2157,  0.3495, -0.1770,  ...,  0.2640, -0.0096,  0.4679]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2203, -0.0463,  0.1329,  ...,  0.0979, -0.3664,  0.3431],\n",
       "          [-0.0973, -0.2557,  0.4457,  ...,  0.1551, -0.3278,  0.6508]],\n",
       "\n",
       "         [[ 0.5532, -0.3937,  0.4316,  ..., -0.0912,  0.6116, -0.1449],\n",
       "          [ 0.6388, -0.4841,  0.4255,  ..., -0.0629,  0.5913, -0.1810]],\n",
       "\n",
       "         [[ 0.4216, -0.3658, -0.3054,  ...,  0.1030,  0.0099, -0.1975],\n",
       "          [ 0.3812, -0.3219, -0.4682,  ..., -0.3154,  0.0673, -0.2982]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[-0.0638, -0.3080,  0.1955,  ..., -0.2980,  0.1688,  0.0431],\n",
       "          [ 0.5026, -0.5220,  3.4995,  ..., -1.0278,  0.1422,  2.3666]],\n",
       "\n",
       "         [[ 0.4591,  0.1555, -0.1794,  ..., -0.2225, -0.4867,  0.2342],\n",
       "          [-0.4296, -0.2702, -0.8925,  ..., -1.1856,  0.8598, -0.2742]],\n",
       "\n",
       "         [[-0.3287, -0.1999, -0.2862,  ..., -0.5182,  0.0972,  0.6838],\n",
       "          [ 2.6562,  1.6259, -1.6430,  ...,  0.5375,  1.0974, -3.0638]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1022, -0.1004,  0.0337,  ..., -0.4126,  0.0917,  0.2785],\n",
       "          [-0.3013,  0.2233, -0.8632,  ..., -2.7654,  0.0675,  2.4467]],\n",
       "\n",
       "         [[ 0.3300,  0.2506,  0.0510,  ..., -0.0276, -0.1510, -0.1070],\n",
       "          [-3.6227,  0.0169, -1.4157,  ..., -0.7226, -1.0749,  1.1248]],\n",
       "\n",
       "         [[-0.0671, -0.4478, -0.0450,  ..., -0.1774, -0.1607, -0.0955],\n",
       "          [-4.6108,  0.6886,  0.8102,  ..., -0.4719,  0.8873, -2.4897]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.0404, -0.0917,  0.0642,  ..., -0.0035, -0.0486,  0.0240],\n",
       "          [-0.2731,  0.0407,  0.5085,  ..., -0.1216, -0.2275, -0.7928]],\n",
       "\n",
       "         [[ 0.0031, -0.1010,  0.0053,  ...,  0.0069, -0.0100,  0.0144],\n",
       "          [-0.1159, -0.6017,  0.1824,  ..., -0.1040,  0.0132,  0.0196]],\n",
       "\n",
       "         [[ 0.1149, -0.0396, -0.0644,  ..., -0.1404,  0.0345,  0.0140],\n",
       "          [ 0.4707,  0.5479,  0.1769,  ..., -1.8493, -0.6008, -0.0666]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0385, -0.0342, -0.0351,  ...,  0.0089, -0.0578,  0.0940],\n",
       "          [ 0.3749,  0.0586, -0.0326,  ..., -0.1291, -0.1929,  0.6304]],\n",
       "\n",
       "         [[-0.0040,  0.0416,  0.0358,  ...,  0.0166,  0.0453,  0.0051],\n",
       "          [ 0.0923, -0.0819,  0.3751,  ...,  0.5956, -0.0576, -0.0671]],\n",
       "\n",
       "         [[ 0.0988,  0.0028,  0.0458,  ...,  0.1539,  0.0561,  0.0554],\n",
       "          [ 0.0944, -0.1632,  0.0327,  ...,  0.9541,  0.3676,  0.2072]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.4540, -0.9974, -2.6459,  ...,  1.1923, -0.3397,  3.7741],\n",
       "          [ 0.5595, -0.9436, -1.4177,  ...,  0.9573, -0.9510,  3.5285]],\n",
       "\n",
       "         [[ 0.5767, -1.4281, -0.0372,  ...,  0.2962,  1.1243,  1.1418],\n",
       "          [-0.3780, -1.4567,  1.4320,  ..., -0.2319,  0.4736,  0.6123]],\n",
       "\n",
       "         [[ 0.4139, -1.4614, -0.8103,  ..., -3.3714,  0.1478,  0.2090],\n",
       "          [-0.1716, -1.2067, -0.2029,  ..., -2.4051, -0.5143,  0.5125]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4578, -0.9712,  0.9847,  ..., -0.2011, -1.6939,  0.2227],\n",
       "          [-1.9282, -0.9421,  0.6625,  ..., -0.3203, -2.4944,  0.4157]],\n",
       "\n",
       "         [[-1.9077,  2.6054,  0.7046,  ...,  3.3153,  0.8114, -1.1166],\n",
       "          [-0.5560,  2.4935,  1.0945,  ...,  3.5782,  0.8835, -1.7877]],\n",
       "\n",
       "         [[-0.7894, -0.6044, -0.4530,  ...,  2.1209, -1.0290,  1.3274],\n",
       "          [-1.5356,  0.6271, -1.3167,  ...,  1.9269, -1.3602,  2.0155]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.2468,  0.4531, -0.2456,  ..., -0.2639, -0.4747,  0.2349],\n",
       "          [ 0.6563,  0.5046, -0.2421,  ...,  0.0345, -0.6680,  0.2661]],\n",
       "\n",
       "         [[ 0.1554,  0.0104,  0.0888,  ...,  0.5652,  0.1155,  0.2966],\n",
       "          [ 0.2705, -0.4564,  0.2788,  ...,  0.3807,  0.1667,  0.0607]],\n",
       "\n",
       "         [[-0.5218, -0.1890,  0.0533,  ..., -0.1139,  0.2080, -0.0636],\n",
       "          [-0.3670, -0.1278, -0.1607,  ...,  0.1446, -0.0988, -0.1946]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0757,  0.8512,  0.1290,  ...,  0.5617,  0.4623, -0.4476],\n",
       "          [-0.1185,  0.9600,  0.4644,  ...,  0.6976,  0.4706,  0.1709]],\n",
       "\n",
       "         [[ 0.0076, -0.1633,  0.0613,  ..., -0.4322, -0.1017,  0.0051],\n",
       "          [ 0.0926, -0.3790,  0.3583,  ..., -0.1947, -0.1139, -0.2700]],\n",
       "\n",
       "         [[ 0.8125,  0.0627,  0.4241,  ...,  0.3436,  0.0131, -0.7254],\n",
       "          [ 0.4459,  0.2707,  0.4448,  ...,  0.2226,  0.4030, -0.7321]]]],\n",
       "       grad_fn=<CloneBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.4624, -0.2475,  0.0902,  ...,  0.1127,  0.6529,  0.2203],\n",
       "         [ 0.4538, -0.2948,  0.2556,  ..., -0.0442,  0.6858,  0.4372]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartModel\n",
    "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "inputs = kobart_tokenizer(['안녕하세요.'], return_tensors='pt')\n",
    "model(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. ainize/kobart-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 hunggingface의 transformers 라이브러리 설치\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.45k/1.45k [00:00<00:00, 267kB/s]\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Downloading: 100%|██████████| 496M/496M [00:22<00:00, 21.6MB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학조사당국이 8차례 인명 수색을 진행한 가운데 8차례 인명 수색을 진행한 가운데 어제 오전 이후 생존자와 사망자가 추가로 나오지\n"
     ]
    }
   ],
   "source": [
    "## 모델과 문장 분리를 위한 토크나이저 불러오기\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "#  Load Model and Tokenize\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"ainize/kobart-news\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"ainize/kobart-news\")\n",
    "\n",
    "## 요약하고자 하는 내용을 입력\n",
    "# Encode Input Text\n",
    "input_text = '''태풍으로 물이 급격히 불어나면서 지하주차장이 침수돼 9명의 실종자를 낸 경북 포항 아파트 침수 사고.\n",
    "\n",
    "이틀간 진행된 배수 작업과 수색 작업이 사실상 마무리됐습니다.\n",
    "\n",
    "소방당국이 모두 8차례 인명 수색을 진행한 가운데 어제 오전 이후 생존자와 사망자는 추가로 나오지 않았습니다.\n",
    "\n",
    "지금까지 구조된 생존자는 30대 남성과 50대 여성 2명입니다.\n",
    "\n",
    "이들 모두 천장과 배관 사이, 30센티미터가 채 되지 않은 좁은 공간에서 약간의 공기층을 찾아 13시간 이상을 견디다 극적으로 구조됐습니다.\n",
    "\n",
    "하지만 이후 발견된 7명은 모두 심정지 상태로 구조됐고, 끝내 숨졌습니다.\n",
    "\n",
    "특히 마지막에 발견된 70대 남성을 제외하고는 모두 차 밖에 있었고, 대부분은 주차장 입구나 지상 연결 계단 근처에서 발견돼, 안타까움을 더했습니다.\n",
    "\n",
    "소방 당국은 물이 찰 때 엄청난 속도로 불어나며 출입구가 막히는 등 한정된 공간에서 탈출하는 게 매우 어려웠을 것이라고 설명했습니다.\n",
    "\n",
    "수색 작업이 마무리된 가운데 사고 원인 규명 작업이 본격화합니다.\n",
    "\n",
    "60여 명의 전담팀을 꾸린 경찰은 아파트 관리 사무소 관계자와 목격자 등을 상대로 탐문 수사를 벌이고, 국립과학수사원과 함께 현장 감식도 진행하며 사고 원인을 찾을 계획입니다.\n",
    "'''\n",
    "\n",
    "## 토크나이저를 사용하여 뉴스기사 원문을 모델이 인식할 수 있는 토큰형태로 바꿈\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "## \n",
    "# Generate Summary Text Ids\n",
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=0.5,                      # 길이에 대한 penalty, 1보다 작은 경우 더 짧은 문장을 생성하도록 유도\n",
    "    max_length=120,                          # 요약문의 최대 길이 설정\n",
    "    min_length=100,                           # 요약문의 최소 길이 설정\n",
    "    num_beams=4,                             # 문장 생성시 다음 단어를 탐색하는 영역의 개수\n",
    ")\n",
    "\n",
    "## 요약결과\n",
    "# Decoding Text\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. gogamza/kobart-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 682k/682k [00:01<00:00, 628kB/s]  \n",
      "Downloading: 100%|██████████| 4.00/4.00 [00:00<00:00, 1.32kB/s]\n",
      "Downloading: 100%|██████████| 111/111 [00:00<00:00, 108kB/s]\n",
      "Downloading: 100%|██████████| 1.18k/1.18k [00:00<00:00, 394kB/s]\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Downloading: 100%|██████████| 496M/496M [00:22<00:00, 21.6MB/s]   \n"
     ]
    }
   ],
   "source": [
    "# 모델과 문장 분리를 위한 토크나이저를 불러옵니다.\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"gogamza/kobart-summarization\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약하고자 하는 기사를 입력합니다.\n",
    "# 기사원문: http://news.heraldcorp.com/view.php?ud=20211127000015\n",
    "news_text = \"세계가 ‘오미크론(Omicron)’ 공포에 빠졌다. 코로나19 델타변이도 잡지 못해 전전긍긍하는데 세계보건기구(WHO)가 또 다른 ‘우려 변이(variant of concern)’로 오미크론을 지정하면서다. 항체를 무력화 수 있는 돌연변이가 많은 걸로 파악되는 오미크론이 코로나19 백신엔 어떤 영향을 미칠지를 보려면 추가 연구가 필요한 상황이다. 각 국은 서둘러 국경의 빗장을 걸고 있다. 미국과 유럽 등 글로벌 증시를 폭락시킨 오미크론은 현재로선 어디로 튈지 모르는 변이여서 두려움을 더하고 있다.\"\n",
    "\n",
    "# 토크나이저를 사용하여 뉴스기사 원문을 모델이 인식할 수 있는 토큰형태로 바꿔줍니다.\n",
    "input_ids = tokenizer.encode(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28589, 14143, 11841, 10746, 13090, 10341, 23601, 308, 16968, 313, 14889, 28102, 19023, 11786, 14621, 24002, 14469, 10338, 9495, 15874, 25863, 13123, 10869, 25933, 23905, 17551, 14038, 12126, 9246, 9246, 16144, 14370, 20126, 17842, 19995, 271, 278, 15092, 14153, 14355, 14143, 11911, 10313, 14296, 12034, 239, 317, 15562, 304, 15195, 315, 19524, 16637, 14889, 298, 14879, 309, 240, 18407, 14075, 10746, 13090, 16298, 16241, 14457, 14130, 14577, 16428, 23582, 13714, 14032, 14082, 14327, 11806, 10869, 15028, 14467, 26185, 15920, 14343, 14075, 10746, 13090, 20983, 14469, 10338, 9495, 15874, 14566, 11467, 11788, 14593, 15587, 20667, 14404, 14046, 16939, 14927, 14541, 8981, 15490, 14431, 16247, 14319, 14071, 12005, 23987, 14071, 21521, 19238, 14324, 23153, 15964, 19593, 15251, 14048, 15365, 14258, 16632, 14556, 10214, 16366, 14075, 10746, 13090, 22686, 14475, 10338, 11268, 26531, 1700, 13312, 12332, 17989, 14296, 12034, 19266, 18018, 15065, 14166, 14058, 15964]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 모델에 넣기 전 문장의 시작과 끝을 나타내는 토큰을 추가합니다.\n",
    "input_ids = [tokenizer.bos_token_id] + input_ids + [tokenizer.eos_token_id]\n",
    "input_ids = torch.tensor([input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=2.0, # 길이에 대한 penalty값. 1보다 작은 경우 더 짧은 문장을 생성하도록 유도하며, 1보다 클 경우 길이가 더 긴 문장을 유도\n",
    "    max_length=128,     # 요약문의 최대 길이 설정\n",
    "    min_length=32,      # 요약문의 최소 길이 설정\n",
    "    num_beams=4,        # 문장 생성시 다음 단어를 탐색하는 영역의 개수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 14370, 20126, 17842, 19995,   271,   278, 15092, 14577, 16428,\n",
      "         23582, 13714, 14207, 14032, 14082, 14327, 11806, 10869, 15028, 14467,\n",
      "         26185, 15920, 14343, 14075, 10746, 13090, 20983, 14469, 10338,  9495,\n",
      "         15874, 14566, 11467, 11788, 14593, 15587, 20667, 14404, 14046, 16939,\n",
      "         14927, 14541,  8981, 15490, 14431, 14027, 14370, 20126, 17842, 19995,\n",
      "           271,   278, 15092, 14370, 20126, 17842, 19995,   271,   278, 15092,\n",
      "         14153, 14355, 14143, 11911, 10313, 14296, 12034, 18407, 14075, 10746,\n",
      "         13090, 16298, 16241, 14457, 15365, 14258, 16632, 14556, 10214, 16366,\n",
      "         14075, 10746, 13090, 22686, 14475, 10338, 11268, 26531,  1700, 13312,\n",
      "         12332, 17989, 14296, 12034, 19266, 18018, 15065, 14166, 14058, 15964,\n",
      "             1]])\n"
     ]
    }
   ],
   "source": [
    "print(summary_text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계보건기구(WHO)가 항체를 무력화 할 수 있는 돌연변이가 많은 걸로 파악되는 오미크론이 코로나19 백신엔 어떤 영향을 미칠지를 보려면 추가 연구가 필요한 상황으로 세계보건기구(WHO)가 세계보건기구(WHO)가 또 다른 ‘우려 변이’로 오미크론을 지정하면서 글로벌 증시를 폭락시킨 오미크론은 현재로선 어디로 튈지 모르는 변이여서 두려움을 더하고 있다.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계보건기구(WHO)가 항체를 무력화 할 수 있는 돌연변이가 많은 걸로 파악되는 오미크론이 코로나19 백신엔 어떤 영향을 미칠지를 보려면 추가 연구가 필요한 상황이다.\n"
     ]
    }
   ],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    length_penalty=1.0, # 길이에 대한 penalty값. 1보다 작은 경우 더 짧은 문장을 생성하도록 유도하며, 1보다 클 경우 길이가 더 긴 문장을 유도\n",
    "    max_length=128,     # 요약문의 최대 길이 설정\n",
    "    min_length=32,      # 요약문의 최소 길이 설정\n",
    "    num_beams=4,        # 문장 생성시 다음 단어를 탐색하는 영역의 개수 \n",
    ")\n",
    "\n",
    "print(tokenizer.decode(summary_text_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
