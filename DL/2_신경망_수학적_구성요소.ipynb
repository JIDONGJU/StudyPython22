{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 데이터 표현\n",
    "- 텐서(tensor)\n",
    "    - 다차원 넘파이 배열\n",
    "    - 데이터를 위한 컨테이너(container), 숫자를 주로 다룸\n",
    "    - 임의의 차원 개수를 가지는 행렬의 일반화된 모습 (차원(dimension)을 종종 축(axis)라고 부름)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스칼라(0D 텐서)\n",
    "- 하나의 숫자만 담고 있는 텐서\n",
    "- 스칼라 텐서, 0차원 텐서, 0D 텐서라고 부름\n",
    "- float32나 float64 타입의 숫자가 스칼라 텐서 (또는 배열 스칼라(array scalar))\n",
    "- 축 개수는 0 (ndim = 0), 텐서의 축 개수를 랭크(rank)라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print(x)      # 스칼라 텐서\n",
    "print(x.ndim) # 축(랭크) 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터(1D 텐서)\n",
    "- 숫자의 배열\n",
    "- 딱 하나의 축을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  3  6 14  7]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12,3,6,14,7])\n",
    "print(x)     \n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 벡터는 5개의 원소를 가지고 있으므로 5차원 벡터라고 부름\n",
    "- 5D 벡터와 5D 텐서 혼동주의!\n",
    "- 차원수(dimensionality)는 특정 축을 따라 놓인 원소의 개수이거나 텐서의 축 개수를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행렬(2D 텐서)\n",
    "- 벡터의 배열이 행렬(matrix)\n",
    "- 행렬에는 2개의 축(행(row), 열(column))\n",
    "- 숫자가 채워진 사각 격자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5,48,2,43,0],\n",
    "             [6,29,2,53,1],\n",
    "             [7,80,4,36,2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번째 축에 놓여있는 원소를 행 이라 부름\n",
    "- 두번째 축에 놓여있는 원소를 열 이라 부름\n",
    "- x의 첫번째 행은 [5,48,2,43,0], 첫번째 열은 [5,6,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D 텐서와 고차원 텐서\n",
    "- 행렬들을 하나의 새로운 배열로 합치면 3D 텐서가 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]], \n",
    "               [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]], \n",
    "               [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]]]) \n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3D 텐서들을 하나의 배열로 합치면 4D 텐서를 만드는 식으로 이어짐\n",
    "- 딥러닝에서는 보통 0D ~ 4D 까지의 텐서를 다룸\n",
    "- 동영상을 다룰 경우에는 5D 텐서까지 가기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 핵심속성\n",
    "- 텐서는 3개의 핵심 속성\n",
    "    - 축 개수(랭크) : 3D 텐서에는 3개의 축, 행렬에는 2개의 축, array.ndim 으로 확인\n",
    "    - 크기(shaep) : 각 축에 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플(tuple)\n",
    "        - 행렬의 경우 (3,5), 3D 텐서의 크기는 (3, 3, 5)\n",
    "        - 벡터의 크기는 (5,) 처럼 1개의 원소로 이루어진 튜플\n",
    "        - 배열 스칼라는 0처럼 크기가 없음\n",
    "    - 데이터 타입(dtype) : 텐서에 포함된 데이터의 타입\n",
    "        - float32, float64, uint8 등\n",
    "        - 드물게 cha 타입 사용\n",
    "        - 텐서는 사전에 할당되어 연속된 메모리에 저장되어야 하므로\n",
    "        - 넘파이 배열은 가변 길이의 문자열을 지원하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANpElEQVR4nO3db6xU9Z3H8c9HtxpDS4TlSpCSvbXyhKwpbSaySbGyaRbUaLAmEokSTIj0ASY2qXENakqMGt0sbWpcmtBVSrUrmrQKD0yRJY3YJ4TRsAqarmggFdF70ZhSo7LY7z64h+aKd35zmf/l+34lNzNzvnPmfDP64cyc35nzc0QIwJnvrH43AKA3CDuQBGEHkiDsQBKEHUji73q5sRkzZsTw8HAvNwmkcvDgQR09etQT1doKu+0rJP1U0tmS/jMiHiw9f3h4WPV6vZ1NAiio1WoNay1/jLd9tqT/kHSlpHmSltue1+rrAeiudr6zXyrpQES8FRHHJW2RtLQzbQHotHbCPlvSH8c9frta9jm2V9uu266Pjo62sTkA7ej60fiI2BgRtYioDQ0NdXtzABpoJ+yHJc0Z9/ir1TIAA6idsO+RNNf212yfI+kGSds60xaATmt56C0iTti+VdJ2jQ29PRYR+zvWGYCOamucPSKek/Rch3oB0EWcLgskQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ioq0pm20flHRM0meSTkRErRNNAei8tsJe+eeIONqB1wHQRXyMB5JoN+wh6XnbL9lePdETbK+2XbddHx0dbXNzAFrVbtgXRsS3JF0paY3t75z6hIjYGBG1iKgNDQ21uTkArWor7BFxuLodkfSMpEs70RSAzms57Lan2P7KyfuSFkva16nGAHRWO0fjZ0p6xvbJ1/mviPhtR7oC0HEthz0i3pL0jQ72AqCLGHoDkiDsQBKEHUiCsANJEHYgiU78EAYDbPfu3cX6448/Xqzv2rWrWN+3r/VTK9avX1+sX3jhhcX6iy++WKyvWLGiYW3BggXFdc9E7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2c8ATz31VMPabbfdVly32aXCIqJYX7RoUbF+9Gjja5HefvvtxXWbadZbadtbtmxpa9t/i9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMPgBMnThTre/bsKdZvueWWhrWPPvqouO7ll19erN9zzz3F+sKFC4v1Tz/9tGFt2bJlxXW3b99erDdTqzGp8Hjs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZB8ATTzxRrK9atarl1168eHGxXvotvCRNnTq15W03e/12x9HnzJlTrK9cubKt1z/TNN2z237M9ojtfeOWTbe9w/Yb1e207rYJoF2T+Rj/C0lXnLLsTkk7I2KupJ3VYwADrGnYI2KXpA9OWbxU0ubq/mZJ13a2LQCd1uoBupkRcaS6/66kmY2eaHu17brterPrnQHonraPxsfYVf8aXvkvIjZGRC0iakNDQ+1uDkCLWg37e7ZnSVJ1O9K5lgB0Q6th3ybp5LjGSklbO9MOgG5pOs5u+0lJiyTNsP22pB9JelDS07ZXSTokqfzD5OTuvvvuYv2BBx4o1m0X62vWrGlYu++++4rrtjuO3sz999/ftdd++OGHi3W+Nn5e07BHxPIGpe92uBcAXcTpskAShB1IgrADSRB2IAnCDiTBT1w74N577y3Wmw2tnXvuucX6kiVLivWHHnqoYe28884rrtvMJ598Uqw///zzxfqhQ4ca1ppNudzsMtZLly4t1vF57NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2Sfpww8/bFjbsGFDcd1mP1FtNo7+7LPPFuvtOHDgQLF+4403Fuv1er3lbV9//fXF+h133NHya+OL2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs0/S8ePHG9bandaq2SWRR0bKc3Bs2rSpYW3r1vIl/ffv31+sHzt2rFhvdg7BWWc13p/cdNNNxXWnTJlSrOP0sGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ5+kc845p2HtggsuKK7bbJx8eHi4WG82lt2O2bNnF+vNpnR+5513ivUZM2Y0rF1zzTXFddFZTffsth+zPWJ737hl62wftr23+ruqu20CaNdkPsb/QtIVEyz/SUTMr/6e62xbADqtadgjYpekD3rQC4AuaucA3a22X6k+5k9r9CTbq23XbdfbPYccQOtaDfvPJH1d0nxJRyStb/TEiNgYEbWIqA0NDbW4OQDtainsEfFeRHwWEX+R9HNJl3a2LQCd1lLYbc8a9/B7kvY1ei6AwdB0nN32k5IWSZph+21JP5K0yPZ8SSHpoKTvd6/FwXD++ec3rDW7rvvVV19drL///vvF+sUXX1ysl+Ypv/nmm4vrTp8+vVi/4YYbivVm4+zN1kfvNA17RCyfYPGjXegFQBdxuiyQBGEHkiDsQBKEHUiCsANJ8BPXDliwYEGxPsinCe/atatYf+GFF4r1Zj+/veiii067J3QHe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uQ+/vjjYr3ZOHqzOj9xHRzs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZk1uyZEm/W0CPsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ09u+/bt/W4BPdJ0z257ju3f2X7N9n7bt1XLp9veYfuN6nZa99sF0KrJfIw/IemHETFP0j9JWmN7nqQ7Je2MiLmSdlaPAQyopmGPiCMR8XJ1/5ik1yXNlrRU0ubqaZslXdulHgF0wGkdoLM9LOmbknZLmhkRR6rSu5JmNlhnte267fogz3kGnOkmHXbbX5b0a0k/iIg/ja9FREiKidaLiI0RUYuI2tDQUFvNAmjdpMJu+0saC/qvIuI31eL3bM+q6rMkjXSnRQCd0HTozWPXCn5U0usR8eNxpW2SVkp6sLrd2pUO0VVvvvlmv1tAj0xmnP3bklZIetX23mrZWo2F/GnbqyQdkrSsKx0C6IimYY+I30tqNBPAdzvbDoBu4XRZIAnCDiRB2IEkCDuQBGEHkuAnrslddtllxfrYyZE4E7BnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdP7pJLLinW586dW6w3+z18qc6Vi3qLPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4O4rWrl1brK9atarl9R955JHiuvPmzSvWcXrYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpOZn32OpF9KmikpJG2MiJ/aXifpFkmj1VPXRsRz3WoU/XHdddcV61u2bCnWd+zY0bC2bt264rqbNm0q1qdMmVKs4/Mmc1LNCUk/jIiXbX9F0ku2T/4X/ElE/Hv32gPQKZOZn/2IpCPV/WO2X5c0u9uNAeis0/rObntY0jcl7a4W3Wr7FduP2Z7WYJ3Vtuu266OjoxM9BUAPTDrstr8s6deSfhARf5L0M0lflzRfY3v+9ROtFxEbI6IWETWuOQb0z6TCbvtLGgv6ryLiN5IUEe9FxGcR8RdJP5d0affaBNCupmG3bUmPSno9In48bvmscU/7nqR9nW8PQKdM5mj8tyWtkPSq7b3VsrWSltuer7HhuIOSvt+F/tBnU6dOLdaffvrpYv2uu+5qWNuwYUNx3WZDc/wE9vRM5mj87yV5ghJj6sDfEM6gA5Ig7EAShB1IgrADSRB2IAnCDiThiOjZxmq1WtTr9Z5tD8imVqupXq9PNFTOnh3IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujpOLvtUUmHxi2aIelozxo4PYPa26D2JdFbqzrZ2z9ExITXf+tp2L+wcbseEbW+NVAwqL0Nal8SvbWqV73xMR5IgrADSfQ77Bv7vP2SQe1tUPuS6K1VPemtr9/ZAfROv/fsAHqEsANJ9CXstq+w/QfbB2zf2Y8eGrF90Partvfa7uuP76s59EZs7xu3bLrtHbbfqG4nnGOvT72ts324eu/22r6qT73Nsf0726/Z3m/7tmp5X9+7Ql89ed96/p3d9tmS/lfSv0h6W9IeScsj4rWeNtKA7YOSahHR9xMwbH9H0p8l/TIi/rFa9m+SPoiIB6t/KKdFxL8OSG/rJP2539N4V7MVzRo/zbikayXdrD6+d4W+lqkH71s/9uyXSjoQEW9FxHFJWyQt7UMfAy8idkn64JTFSyVtru5v1tj/LD3XoLeBEBFHIuLl6v4xSSenGe/re1foqyf6EfbZkv447vHbGqz53kPS87Zfsr26381MYGZEHKnuvytpZj+bmUDTabx76ZRpxgfmvWtl+vN2cYDuixZGxLckXSlpTfVxdSDF2HewQRo7ndQ03r0ywTTjf9XP967V6c/b1Y+wH5Y0Z9zjr1bLBkJEHK5uRyQ9o8Gbivq9kzPoVrcjfe7nrwZpGu+JphnXALx3/Zz+vB9h3yNpru2v2T5H0g2StvWhjy+wPaU6cCLbUyQt1uBNRb1N0srq/kpJW/vYy+cMyjTejaYZV5/fu75Pfx4RPf+TdJXGjsi/KemufvTQoK+LJP1P9be/371JelJjH+v+T2PHNlZJ+ntJOyW9Iem/JU0foN4el/SqpFc0FqxZfeptocY+or8iaW/1d1W/37tCXz153zhdFkiCA3RAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/A38cJNEbCe0NAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 구체적으로 확인\n",
    "# mnist 데이터셋 불러오기\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# train_images 배열의 ndim 속성으로 축 개수 확인\n",
    "print(train_images.ndim) # 3\n",
    "\n",
    "# 배열의 크기\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "\n",
    "# dtype로 데이터 타입 확인\n",
    "print(train_images.dtype) # uint8\n",
    "\n",
    "# 이 배열은 정수형 3D 텐서 (28*28 크기의 행렬 6만개가 있는 배열)\n",
    "# 각 행렬은 하나의 흑백 이미지\n",
    "# 행렬의 각 원소는 0에서 255사이의 값을 가짐\n",
    "\n",
    "# 다섯번째 이미지 출력\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[4], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 넘파이로 텐서 조작하기\n",
    "- 배열에 있는 특정 원소들을 선택하는 것이 슬라이싱(slicing)이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n",
      "(90, 28, 28)\n",
      "(60000, 14, 14)\n",
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# 11번째에서 100번째까지 숫자를 선택하여 (90,28,28)크기의 배열 만들기\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape) # (90, 28, 28)\n",
    "\n",
    "# 더 자세한 표기법\n",
    "# 각 배열의 축을 따라 슬라이싱의 시작 인덱스와 마지막 인덱스 지정\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape) # (90, 28, 28)\n",
    "\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape) # (90, 28, 28)\n",
    "\n",
    "# 각 배열의 축을 따라 어떤 인덱스 사이도 선택 가능\n",
    "# 14x14픽셀을 선택하려면 아래와 같이\n",
    "my_slice = train_images[:, 14:, 14:]\n",
    "print(my_slice.shape) # (60000, 14, 14)\n",
    "\n",
    "# 음수 인덱스도 사용 가능\n",
    "# 현재 축의 끝에서 상대적인 위치를 나타냄\n",
    "# 정중앙에 위치한 14x14 픽셀 조각 잘라내기\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "print(my_slice.shape) # (60000, 14, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 데이터\n",
    "- 딥러닝에서 사용하는 모든 데이터 텐서의 첫번째 축(인덱스 0번째 축)은 샘플 축(sample axis)\n",
    "- 샘플 차원(sample dimension)이라고도 부름\n",
    "- 딥러닝 모델은 한번에 전체 데이터셋을 처리하지 않음\n",
    "- 대신 작은 배치(batch)로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 숫자 데이터에서 크기가 128인 배치 하나\n",
    "batch = train_images[:128]\n",
    "\n",
    "# 그 다음 배치\n",
    "batch = train_images[128:256]\n",
    "\n",
    "# n번째 배치\n",
    "# batch = train_images[128 * n : 128 * (n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치 데이터를 다룰 때는 첫번째 축(0번째)을 배치 축(batch axis) 또는 배치차원(batch dimension)이라 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 실제 사례\n",
    "- 우리가 사용할 데이터는 대부분 다음 중 하나\n",
    "    - 벡터 데이터 : (samples, teatures) 크기의 2D 텐서\n",
    "    - 시계열 데이터 or 시퀀스 데이터 : (samples, timesteps, features) 크기의 3D 텐서\n",
    "    - 이미지 : (samples, height, width, channels) 또는 (sample, channels, height, width) 크기의 4D 텐서\n",
    "    - 동영상 : (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터 데이터\n",
    "- 대부분의 경우에 해당\n",
    "- 하나의 데이터 포인트가 벡터로 인코딩 될 수 있으므로 배치 데이터는 2D 텐서로 인코딩 될 것(벡터의 배열)\n",
    "- 첫번째 축은 샘플 축, 두번째 축은 특성 축(feature axis)\n",
    "- 예시)1\n",
    "    - 사람의 나이, 우편 번호, 인구 통계 데이터. 각 사람은 3개의 값을 가진 벡터로 구성되고\n",
    "    - 10만 명이 포함된 전체 데이터 셋은 (100000,3) 크기의 텐서에 저장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시계열 데이터 또는 시퀀스 데이터\n",
    "- 데이터에서 시간이(또는 연속된 순서가) 중요할 때는 시간 축을 포함하여 3D 텐서로 저장\n",
    "- 각 샘플은 벡터의 시퀀스로 인코딩되므로 배치 데이터는 3D 텐서로 인코딩 될 것\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/068.jpg?w=300&h=151' width ='40%' height='40%'/>\n",
    "- 관례적으로 시간 축은 항상 두번째 축(인덱스가 1인 축)임\n",
    "- 예시\n",
    "    - 주식 가격 데이터셋 : 1분마다 현재 주식 가격, 지난 1분동안 최고가격과 최소가격 저장\n",
    "    - 1분마다 데이터는 3D 벡터로 인코딩되고 하루동안의 거래는 (390,3) 크기의 2D 텐서로 인코딩\n",
    "    - 250일치의 데이터는 (250, 390, 3) 크기의 3D 텐서로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 데이터\n",
    "- 이미지는 전형적으로 높이, 너비, 컬러 채널의 3차원으로 이루어짐\n",
    "- 흑백 이미지의 경우 컬러 채널의 차원 크기 1\n",
    "- 256x256 크기의 흑백 이미지에 대한 128개 배치는 (128, 256, 256, 1)크기의 텐서에 저장\n",
    "- 컬러 이미지에 대한 128개의 배치라면 (128, 256, 256, 3) 크기의 텐서에 저장 될 수 있음\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/069.jpg?w=300&h=287' width ='40%' height='40%'/>\n",
    "- 이미지 텐서의 크기를 지정하는 방식은 두가지\n",
    "- 텐서플로에서 사용하는 채널 마지막(channel-last)방식과 씨아노에서 사용하는 채널 우선(channel-firts)\n",
    "- 구글의 텐서플로 머신러닝 프레임워크는 (samples, height, width, color_depth)처럼 컬러 채널의 깊이를 끝에\n",
    "- 씨아노는 (samples, color_depth, height, width)처럼 컬러 채널의 깊이를 배치 축 바로 뒤에\n",
    "- 케라스 프레임워크는 두 형식 모두 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비디오 데이터\n",
    "- 현실에서 5D 텐서가 필요한 몇 안되는 데이터 중 하나\n",
    "- 하나의 비디오는 프레임의 연속이고 각 프레임은 하나의 컬러 이미지\n",
    "- 프레임이 (height, width, color_depth)의 3D 텐서로 저장될 수 있기 때문에\n",
    "- 프레임의 연속은 (frames, height, width, color_depth)의 4D 텐서로 저장될 수 있음\n",
    "- 여러 비디오의 배치는 (samples, frames, height, width, color_depth)의 5D 텐서로 저장\n",
    "- 예시\n",
    "    - 60초짜리 144x256 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240프레임이 됨\n",
    "    - 이런 비디오 클립을 4개 가진 배치는 (4, 240, 144, 256, 3) 크기의 텐서에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망의 톱니바퀴 : 텐서 연산\n",
    "- 심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산으로 나타낼 수 있음\n",
    "- ex) 텐서 덧셈, 턴서 곱셈\n",
    "- 케라스 층은 다음과 같이 생성\n",
    "    - keras.layers.Dense(512, activation='relu')\n",
    "    - 이 층은 2D 텐서를 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 2D 텐서를 반환하는 함수처럼 해석\n",
    "    - 이 함수는 다음과 같음 (w는 2D 텐서, b는 벡터, 둘 다 층의 속성)\n",
    "    - output = relu(dot(w, input) + b)\n",
    "    - 3개의 텐서 연산\n",
    "    - 입력 텐서와 텐서 W 사이의 점곱(dot), 점곱의 결과인 2D 텐서와 벡터 b 사이의 덧셈(+), 마지막 relu연산\n",
    "    - relu(x)는 max(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원소별 연산\n",
    "- relu 함수와 덧셈은 원소별 연산(element-wise operation)\n",
    "- 이 연산은 텐서에 있는 각 원소에 독립적으로 적용 = 고도의 병렬 구현이 가능한 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬으로 단순한 원소별 연산을 구현한다면\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # x는 2D 넘파이 배열\n",
    "    x = x.copy()             # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j], 0)\n",
    "    return x\n",
    "\n",
    "# 덧셈도 동일\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2  # x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy()              # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 같은 원리로 원소별 곱셈, 뺄셈 등 가능\n",
    "- 사실 넘파이 내장 함수로 연산 처리 가능\n",
    "- 넘파이는 시스템에 설치된 BLAS(Basic Linear Algebra Subprogram) 구현에 복잡한 일들을 위임\n",
    "- 넘파이는 원소별 연산을 엄청난 속도로 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 브로드캐스팅\n",
    "- 덧셈 구현인 naive_add는 동일한 크기의 2D 텐서만 지원\n",
    "- 크기가 다른 두 텐서를 더할 때 브로드캐스팅 사용\n",
    "- 작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅 됨\n",
    "    1. 큰 텐서 ndim에 맞도록 작은 텐서에 축이 추가됨\n",
    "    2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복\n",
    "    3. 예시)\n",
    "        - x의 크기는 (32,10)이고 y의 크기는 (10,)라고 가정\n",
    "        - y에 비어있는 첫번째 축을 추가하여 (1,10)으로 만듬\n",
    "        - 32번 반복하여 (32,10)이 됨\n",
    "        - x와 y의 크기가 같으므로 더할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 점곱\n",
    "- 텐서 곱셈(tensor product)이라고도 부르는 점곱 연산은 가장 널리 사용되고 유용한 텐서 연산\n",
    "- 원소별 연산과 반대로 입력 텐서의 원소들을 결합\n",
    "- 넘파이, 케라스, 씨아노, 텐서플로에서 원소별 곱셈은 * 연산자 사용\n",
    "- 넘파이와 케라스는 점곱 연산에 보편적인 dot 연산자 사용\n",
    "- 두 벡터의 점곱은 스칼라가 되므로 원소 개수가 같은 벡터끼리 점곱이 가능\n",
    "- 행렬 x와 벡터 y 사이에서도 점곱이 가능 => 벡터 반환\n",
    "- 두 텐서 중 하나라도 ndim이 1보다 크면 dot 연산에 교환법칙이 성립되지 않음\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/075.jpg?w=468&h=413' width ='40%' height='40%'/>\n",
    "- x, y, z는 직사각형 모양으로 그려 있음(원소들이 채워진 박스라고 이해)\n",
    "- x의 행 벡터와 y의 열 벡터가 같은 크기여야 하므로 자동으로 x의 너비와 y의 높이는 동일해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 크기 변환(tensor reshaping)\n",
    "- 텐서의 크기를 변환한다는 것은 특정 크기에 맞게 행과 열을 재배열한다는 뜻\n",
    "- 당연히 크기가 변환된 텐서는 원래 텐서와 원소 개수가 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "print(x.shape)\n",
    "\n",
    "x = x.reshape((6, 1))\n",
    "print(x)\n",
    "\n",
    "x = x.reshape((2, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자주 사용하는 특별한 크기 변환은 전치(transposition)\n",
    "- 행렬의 전치는 행과 열을 바꾸는 것, x[i, j] => x[j, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20)) # 0으로 채워진 (300, 20) 크기의 행렬\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 연산의 기하학적 해석\n",
    "- 텐서 연산이 조작하는 텐서의 내용은 어떤 기하학적 공간에 있는 좌표 포인트로 해석 가능\n",
    "- 따라서 모든 텐서 연산은 기하하적 해석이 가능\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/077_1.jpg?w=308&h=320' width ='40%' height='40%'/> <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/077_2.jpg?w=309&h=320' width ='40%' height='40%'/>\n",
    "- 이 포인트는 2D 공간에 있고 원점에서 포인트를 연결하는 화살표로 벡터를 나타냄\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/078.jpg?w=300&h=276' width ='40%' height='40%'/>\n",
    "- 새로운 포인트 B = [1, 0.25]를 이전 벡터에 더하기\n",
    "- 기하학적으로 벡터 화살표를 연결하여 계산 가능\n",
    "- 최종 위치는 두 벡터의 덧셈을 나타내는 벡터가 됨\n",
    "- \n",
    "- 일반적으로 아핀변환, 회전, 스케일링 등 기본적인 기하학적 연산은 텐서 연산으로 표현 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딥러닝의 기하학적 해석\n",
    "- 신경망은 전체적으로 텐서 연산의 연결로 구성된 것\n",
    "- 모든 텐서 연산은 입력데이터의 기하학적 변환임\n",
    "- => 단순한 단계들이 이어져 구현된 신경망을 고차원 공간에서 매우 복잡한 기하학적 변환을 하는 것으로 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망의 엔진 : 그래디언트 기반 최적화\n",
    "- 첫번째 신경망 예제에 있는 각 층은 입력 데이터를 다음과 같이 변환\n",
    "- output = relu(dot(w, input) * b)\n",
    "- 이 식에서 텐서 W와 b는 층의 속성\n",
    "- 가중치(weight) 또는 훈련되는 파라미터(trainable parameter)라고 부름(각각 커널(kernel), 편향(bias)이라고도 함)\n",
    "- 가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초기에는 가중치 행렬이 작은 난수로 채워져 있음(무작위 초기화(random initialization)단계)\n",
    "- w와 b가 난수일 떄 output식이 유용한 어떤 표현을 만들 것이라 기대 안하지만 시작 단계\n",
    "- 피드백 신호에 기초하여 가중치가 점진적인 조정 또는 훈련이 머신러닝의 핵심"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련은 다음과 같은 훈련 루프(training loop) 안에서 필요한 만큼 반복\n",
    "    1. 훈련 샘플 x와 이에 상응하는 타깃 y의 배치를 추출\n",
    "    2. x를 사용하여 네트워크를 실행하고(정방향 패스(forward pass)단계), 예측 y_pred를 구함\n",
    "    3. y_pred와 y의 차이를 측정하여 이 배치에 대한 네트워크의 손실을 계산\n",
    "    4. 배치에 대한 손실이 조금 감소하도록 네트워크의 모든 가중치를 업데이트\n",
    "\n",
    "- 결국 훈련 데이터에서 네트워크의 손실, 예측 y_pred와 타깃 y의 오차가 매우 작아질 것\n",
    "- 이 네트워크는 입력에 정확한 타깃을 매핑하는 것을 학습\n",
    "- 1단계는 그냥 입출력 코드, 2단계와 3단계는 몇개의 텐서 연산 적용\n",
    "- 4단계에서 개별적인 가중치 값이 있을 때 증가해야 할지, 감소해야 할지, 얼마나 업데이트 해야할지 고민\n",
    "    - 신경망에 사용된 모든 연산이 '미분가능'하다는 장점을 사용하여\n",
    "    - 네트워크 가중치에 대한 손실의 그래디언트를 계산하는 것이 효과적인 방법\n",
    "    - 그래디언트의 반대방향으로 가중치를 이동하면 손실이 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변화율이란\n",
    "- f(x) = y , 함수가 연속적이므로 x를 조금 바꾸면 y도 조금 변경됨 => 연속성의 개념\n",
    "- x가 이동할 때, y의 변화량 => 기울기 => 변화율(derivative)\n",
    "- <img src = 'https://tensorflowkorea.files.wordpress.com/2018/12/081.jpg?w=300&h=223' width ='40%' height='40%'/>\n",
    "- 모든 미분 가능한 함수 f(x)에 대해 x의 값을 f의 국부적인 선형 근사인 그 지점의 기울기로 매핑하는 변화율 f'(x)가 존재\n",
    "    - ex) cos(x)의 변화율은 -sin(x)이고, f(x)=a*x의 변화율은 f'(x)=a\n",
    "- f(x)를 최소화하기 위해 x이동거리 만큼 x를 업데이트 하고 싶을 때, f의 변화율을 알고 있으면 해결\n",
    "- 변화율 함수는 x가 바뀜에 따라 f(x)가 어떻게 바뀔지 설명해줌\n",
    "- f(x)의 값을 감소시키고 싶다면 x를 변화율의 방향과 반대로 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 연산의 변화율 : 그래디언트\n",
    "- 그래디언트는 텐서 연산의 변화율 : 텐서를 입력으로 받는 함수에 변화율 개념을 확장\n",
    "- 입력 벡터 x, 행렬 w, 타깃 y와 손실함수 loss가 있다고 가정\n",
    "- w를 사용하여 타깃의 예측 y_pred를 계산하고 손실, y_pred와 y의 오차를 계산할 수 있음\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38ae1ba9371524da054e8e3fbefd778d16b5a8ac7937a3f395010f627bb73919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
